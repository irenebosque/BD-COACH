,0,1,2,3
Accumulated time steps,0.0,103.0,215.0,303.0
Episode reward,0.0,63.86589511223968,64.07431955877227,62.94503413850673
Episode feedback,0.8,0.5148514800509755,0.2972972946189433,0.37931034046769724
total seconds,0.0,21.872129440307617,45.42333984375,66.50316977500916
total minutes,0.0,0.36453549067179364,0.7570556640625,1.1083861629168192
cummulative feedback,0.0,52.0,85.0,118.0
e,0.5,0.5,0.5,0.5
buffer size,10000.0,10000.0,10000.0,10000.0
human model,1.0,1.0,1.0,1.0
tau,0.0001,0.0001,0.0001,0.0001
total_success,0.0,1.0,2.0,3.0
total_success_div_episode,0.0,1.0,1.0,1.0
total_policy_loss_agent,0.0,0.0,0.0,0.0
total_policy_loss_hm,0.0,0.06019280105829239,0.050493523478507996,0.03944519907236099
success_this_episode,0.0,1.0,1.0,1.0
timesteps_this_episode,0.0,101.0,111.0,87.0
