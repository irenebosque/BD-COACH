,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,1000.0,1876.0,2875.0,3874.0,4873.0,5872.0,6871.0,7870.0,8869.0,9868.0,10867.0,11866.0,12865.0,13864.0,14863.0,15862.0,16861.0,17860.0,18859.0,19858.0,20857.0
Episode reward,0.0,-47.27854564628375,59.95189048112494,-43.551203702364155,-43.84417038646992,-41.328931401448884,-41.77606870276348,-39.03852611742415,-40.88316670495466,-38.05822431648075,-39.24780751926307,-38.676043852477925,-38.47455986178764,-38.57717279801086,-38.558139399041664,-38.76005361587613,-38.23063163130995,-37.43748453831568,-38.15505192690921,-38.330600581072325,-37.30606467318582,-38.84449770084882
Episode feedback,0.8,0.46793587127461334,0.3074285710772245,0.18637274530423573,0.13727454896064675,0.10721442875028614,0.048096192336576964,0.04208416829450484,0.01903807613322838,0.01603206411219232,0.0200400801402404,0.012024048084144241,0.0060120240420721205,0.00200400801402404,0.0030060120210360602,0.00100200400701202,0.0,0.0,0.0,0.0,0.0,0.00100200400701202
total seconds,0.0,68.99807214736938,124.4384024143219,180.62708592414856,234.92733359336853,287.46870970726013,337.53396582603455,387.3270320892334,435.8919279575348,484.16470742225647,533.2614436149597,581.7640688419342,630.0773389339447,678.1719119548798,726.338476896286,774.0443406105042,821.9045140743256,870.2261021137238,918.0925242900848,965.647210597992,1013.768816947937,1061.541732788086
total minutes,0.0,1.149967869122823,2.0739733735720316,3.0104514320691425,3.9154555598894754,4.791145161787669,5.625566097100576,6.455450534820557,7.264865465958914,8.06941179037094,8.887690726915995,9.696067814032236,10.501288982232412,11.302865199247996,12.105641281604766,12.90073901017507,13.698408567905426,14.503768368562062,15.301542071501414,16.0941201766332,16.896146949132284,17.692362213134764
cummulative feedback,0.0,467.0,736.0,922.0,1059.0,1166.0,1214.0,1256.0,1275.0,1291.0,1311.0,1323.0,1329.0,1331.0,1334.0,1335.0,1335.0,1335.0,1335.0,1335.0,1335.0,1336.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,998.0,875.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
