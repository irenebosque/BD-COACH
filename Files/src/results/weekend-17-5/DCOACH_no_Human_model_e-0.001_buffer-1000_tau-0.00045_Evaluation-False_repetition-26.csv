,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,773.0,1118.0,2117.0,3116.0,4115.0,5114.0,6113.0,7112.0,8111.0,9110.0,10109.0,11108.0,12107.0,13106.0,14105.0,15104.0,16103.0,17102.0,18101.0,19100.0,20099.0
Episode reward,0.0,60.02559727232761,84.16113778578469,-42.542552285830794,-40.594353881877765,-38.3581544917426,-38.770299176366365,-39.91882785070348,-39.28525720702068,-40.903604066838135,-39.82132002816236,-39.96783610495123,-40.838707204361,-38.542338115494566,-39.03015855127498,-40.85519249786691,-38.95719593818883,-40.22460130955755,-39.28146397592916,-40.87808916728996,-39.52440313771555,-40.05749202938109
Episode feedback,0.8,0.45914396827607784,0.398255812795768,0.29258517004750983,0.21142284547953621,0.16232464913594724,0.09118236463809383,0.06412825644876928,0.0450901803155409,0.024048096168288482,0.02104208414725242,0.0100200400701202,0.00200400801402404,0.00400801602804808,0.00200400801402404,0.00100200400701202,0.00100200400701202,0.00100200400701202,0.0,0.00100200400701202,0.0,0.0
total seconds,0.0,63.595460414886475,93.46651887893677,170.435560464859,236.9693055152893,297.56328415870667,351.8723750114441,404.8045060634613,456.5333912372589,506.5807194709778,556.5063772201538,605.6492841243744,654.3125483989716,703.0577924251556,751.6360754966736,800.3256223201752,848.68186378479,897.4883601665497,946.2350301742554,995.4632933139801,1044.6353318691254,1094.112930059433
total minutes,0.0,1.059924340248108,1.5577753146489461,2.840592674414317,3.9494884252548217,4.959388069311777,5.864539583524068,6.746741767724355,7.608889853954315,8.443011991182964,9.275106287002563,10.09415473540624,10.90520913998286,11.717629873752594,12.52726792494456,13.33876037200292,14.1446977297465,14.958139336109161,15.77058383623759,16.591054888566337,17.410588864485423,18.23521550099055
cummulative feedback,0.0,354.0,491.0,783.0,994.0,1156.0,1247.0,1311.0,1356.0,1380.0,1401.0,1411.0,1413.0,1417.0,1419.0,1420.0,1421.0,1422.0,1422.0,1423.0,1423.0,1423.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,771.0,344.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
