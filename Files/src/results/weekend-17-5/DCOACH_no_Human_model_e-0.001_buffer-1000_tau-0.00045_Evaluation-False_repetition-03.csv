,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,954.0,1845.0,2844.0,3843.0,4842.0,5841.0,6840.0,7839.0,8838.0,9837.0,10836.0,11835.0,12834.0,13833.0,14832.0,15831.0,16830.0,17829.0,18828.0,19827.0,20826.0
Episode reward,0.0,58.33218854403681,63.866241315394035,-36.64028444768972,-36.777234330667305,-36.36247589068983,-33.12345870126616,-30.703713113676155,-32.54883377123396,-32.424375430678786,-33.424515609391015,-32.093562771282855,-31.49095304215834,-32.575166732953306,-33.07515082434367,-32.99955731487869,-31.90497523193797,-33.57534336466139,-33.35855310757491,-30.229009242009585,-33.946952276233944,-31.43766550227382
Episode feedback,0.8,0.4600840331301638,0.3393258423153642,0.21743486952160834,0.14428857700973088,0.12424849686949048,0.0651302604557813,0.054108216378649085,0.025050100175300502,0.0150300601051803,0.007014028049084141,0.012024048084144241,0.00400801602804808,0.0030060120210360602,0.0,0.0,0.00100200400701202,0.00100200400701202,0.0,0.0,0.0,0.0
total seconds,0.0,65.52118396759033,124.2370297908783,183.0008089542389,237.82436299324036,292.2493305206299,343.45989418029785,394.3503966331482,443.91062355041504,493.3801517486572,541.8042778968811,590.4849302768707,638.7109525203705,686.679568529129,734.593777179718,782.1777987480164,829.9288594722748,877.9715111255646,925.9091439247131,973.5199146270752,1021.4930295944214,1069.2952737808228
total minutes,0.0,1.0920197327931722,2.070617163181305,3.050013482570648,3.9637393832206724,4.870822175343831,5.724331569671631,6.57250661055247,7.3985103925069176,8.223002529144287,9.030071298281351,9.841415504614512,10.645182542006175,11.444659475485484,12.243229619661967,13.036296645800272,13.832147657871246,14.63285851875941,15.431819065411885,16.225331910451253,17.02488382657369,17.821587896347047
cummulative feedback,0.0,438.0,740.0,957.0,1101.0,1225.0,1290.0,1344.0,1369.0,1384.0,1391.0,1403.0,1407.0,1410.0,1410.0,1410.0,1411.0,1412.0,1412.0,1412.0,1412.0,1412.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,952.0,890.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
