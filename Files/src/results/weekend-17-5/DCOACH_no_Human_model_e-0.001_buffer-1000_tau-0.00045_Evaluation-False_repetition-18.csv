,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,889.0,1648.0,2647.0,3646.0,4645.0,5644.0,6643.0,7642.0,8641.0,9640.0,10639.0,11638.0,12637.0,13636.0,14635.0,15634.0,16633.0,17632.0,18631.0,19630.0,20629.0
Episode reward,0.0,58.390625519554476,64.01030496414683,-42.41882818173526,-41.28108755077573,-39.300534174713974,-39.2766081879829,-38.03613322438178,-39.04816419130286,-37.93815106597664,-38.4349565786177,-37.52985061671396,-38.57063995029441,-36.51327381726036,-38.41946636496729,-36.797488716511396,-34.88138469631848,-38.10465625062057,-36.104305223724964,-37.613528222332086,-36.80688534507587,-35.88778557310196
Episode feedback,0.8,0.4103720401235941,0.286279682999631,0.20741482945148815,0.13827655296765876,0.09318637265211786,0.06813627247681736,0.0450901803155409,0.026052104182312522,0.014028056098168281,0.012024048084144241,0.007014028049084141,0.007014028049084141,0.00400801602804808,0.0030060120210360602,0.00200400801402404,0.0,0.0,0.0,0.0,0.0,0.0
total seconds,0.0,60.75160360336304,108.69474124908447,171.11582851409912,226.69591188430786,279.0724835395813,329.8643522262573,379.75751996040344,428.3856625556946,476.93930077552795,524.9383790493011,572.8599584102631,621.3731529712677,668.9839317798615,716.6752171516418,764.3050193786621,811.7671501636505,859.4955599308014,907.1139340400696,956.3544611930847,1006.3290088176727,1055.1459064483643
total minutes,0.0,1.0125267267227174,1.8115790208180746,2.8519304752349854,3.778265198071798,4.651208058993022,5.497739203770956,6.329291999340057,7.13976104259491,7.948988346258799,8.748972984155019,9.547665973504385,10.356219216187794,11.149732196331025,11.944586952527365,12.738416989644369,13.529452502727509,14.32492599884669,15.118565567334493,15.939241019884745,16.772150146961213,17.58576510747274
cummulative feedback,0.0,364.0,581.0,788.0,926.0,1019.0,1087.0,1132.0,1158.0,1172.0,1184.0,1191.0,1198.0,1202.0,1205.0,1207.0,1207.0,1207.0,1207.0,1207.0,1207.0,1207.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,887.0,758.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
