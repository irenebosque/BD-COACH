,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,715.0,1104.0,1667.0,2666.0,3665.0,4664.0,5663.0,6662.0,7661.0,8660.0,9659.0,10658.0,11657.0,12591.0,13590.0,14589.0,15495.0,16494.0,17493.0,18492.0,19147.0
Episode reward,0.0,72.58589568478186,81.52137005718748,72.42940163229952,-45.274368827074056,-47.69324741663003,-62.65730163181987,-56.92868000341293,-61.77756303368504,-59.748752023405345,-55.94206895727272,-52.7433920548389,-64.71563360212048,-46.77358264015225,58.31035685440365,-51.89635767809173,-52.44938733446996,44.65338785414442,-62.86808454794112,-58.77163365324516,-51.15970548904944,64.50275864671534
Episode feedback,0.8,0.500701261569844,0.23453608186975236,0.23309608499449094,0.2354709416478247,0.12424849686949048,0.00801603205609616,0.050100200350601004,0.00901803606310818,0.01703406811920434,0.01102204407713222,0.00901803606310818,0.0030060120210360602,0.00100200400701202,0.001071811360051649,0.0,0.0,0.0011049723744696437,0.0,0.00100200400701202,0.0,0.0
total seconds,0.0,48.514822244644165,71.85013508796692,104.8672947883606,162.57841873168945,215.52695965766907,262.5168676376343,312.29400086402893,361.15514278411865,410.676127910614,460.37596464157104,510.2430856227875,559.988431930542,610.2091619968414,657.0506148338318,707.0040426254272,756.9915223121643,802.3070805072784,852.6379814147949,902.5626134872437,952.5477120876312,985.3128871917725
total minutes,0.0,0.8085803707440694,1.1975022514661153,1.7477882464726766,2.709640312194824,3.5921159942944842,4.3752811272939045,5.204900014400482,6.019252379735311,6.844602131843567,7.672932744026184,8.504051427046457,9.3331405321757,10.170152699947357,10.950843580563863,11.783400710423788,12.616525371869406,13.371784675121308,14.210633023579915,15.042710224787394,15.875795201460521,16.421881453196207
cummulative feedback,0.0,357.0,448.0,579.0,814.0,938.0,946.0,996.0,1005.0,1022.0,1033.0,1042.0,1045.0,1046.0,1047.0,1047.0,1047.0,1048.0,1048.0,1049.0,1049.0,1049.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,713.0,388.0,562.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,933.0,998.0,998.0,905.0,998.0,998.0,998.0,654.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
