,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,1000.0,1999.0,2998.0,3997.0,4996.0,5995.0,6994.0,7993.0,8992.0,9991.0,10990.0,11989.0,12988.0,13987.0,14986.0,15985.0,16984.0,17983.0,18982.0,19981.0,20980.0
Episode reward,0.0,-45.636384978012714,-43.57589270049148,-42.43617716978609,-43.01858395706537,-41.72318587823589,-40.91338298210083,-41.28159635039536,-40.398659918061064,-42.39904403970774,-42.147289608446194,-41.586763742446585,-43.14737936736591,-42.63390581369991,-43.22174211107506,-42.65559340897816,-42.549625820799214,-41.67408451143997,-42.34214982761732,-41.607061334475574,-42.003341526300716,-42.22306110153771
Episode feedback,0.8,0.40681362684688016,0.2695390778862334,0.23647294565483673,0.11923847683443038,0.09719438868016594,0.048096192336576964,0.027054108189324542,0.0200400801402404,0.01903807613322838,0.007014028049084141,0.0030060120210360602,0.00400801602804808,0.00200400801402404,0.00400801602804808,0.0,0.00100200400701202,0.00100200400701202,0.0,0.0,0.0,0.0
total seconds,0.0,72.79505157470703,138.47786927223206,199.28063011169434,253.07821393013,305.80120754241943,355.80509972572327,405.22101855278015,454.1484115123749,503.07628536224365,551.370007276535,599.3000702857971,647.1436166763306,694.8960008621216,742.7620499134064,790.5330781936646,838.4100961685181,886.0629539489746,933.5673396587372,981.6534647941589,1030.7518627643585,1080.8384613990784
total minutes,0.0,1.2132508595784506,2.3079644878705343,3.3213438351949054,4.217970232168834,5.096686792373657,5.930084995428721,6.753683642546336,7.569140191872915,8.384604756037394,9.189500121275584,9.988334504763285,10.785726944605509,11.581600014368693,12.379367498556773,13.175551303227742,13.973501602808634,14.767715899149577,15.559455660978953,16.36089107990265,17.17919771273931,18.013974356651307
cummulative feedback,0.0,406.0,675.0,911.0,1030.0,1127.0,1175.0,1202.0,1222.0,1241.0,1248.0,1251.0,1255.0,1257.0,1261.0,1261.0,1262.0,1263.0,1263.0,1263.0,1263.0,1263.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
