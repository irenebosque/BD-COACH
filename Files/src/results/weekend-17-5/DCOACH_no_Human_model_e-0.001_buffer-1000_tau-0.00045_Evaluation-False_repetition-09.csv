,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,730.0,1729.0,2728.0,3727.0,4726.0,5725.0,6724.0,7723.0,8722.0,9721.0,10720.0,11719.0,12718.0,13717.0,14716.0,15715.0,16714.0,17713.0,18712.0,19711.0,20710.0
Episode reward,0.0,70.07384441386499,-37.20822421633933,-35.974883342662125,-35.07485014536674,-36.0105692872714,-32.61971390780025,-33.512164095743636,-33.26705185777289,-34.02700799604642,-34.06069925261594,-33.1569350468403,-33.48812987840667,-34.36357959683017,-33.99700815547398,-33.48943602137387,-32.42896353486402,-32.40953298511486,-33.98697663380212,-34.97657548145293,-33.904280574052834,-34.39349594229591
Episode feedback,0.8,0.4986263729414473,0.33567134234902674,0.21342685349356028,0.150300601051803,0.08917835662406978,0.08316633258199767,0.03807615226645676,0.024048096168288482,0.01603206411219232,0.00901803606310818,0.00400801602804808,0.0030060120210360602,0.00901803606310818,0.00400801602804808,0.00100200400701202,0.0,0.0,0.0,0.0,0.0,0.0
total seconds,0.0,61.34913969039917,131.0637185573578,191.06550192832947,250.78463006019592,306.4967143535614,358.3258078098297,407.9743182659149,456.7597019672394,505.2466857433319,553.6515691280365,601.3199007511139,649.1036274433136,697.4153668880463,745.3991446495056,793.0650448799133,840.9186460971832,888.9705877304077,936.6340856552124,984.5311808586121,1032.6611852645874,1082.5670540332794
total minutes,0.0,1.0224856615066529,2.1843953092892963,3.1844250321388246,4.179743834336599,5.108278572559357,5.972096796830495,6.799571971098582,7.61266169945399,8.420778095722198,9.227526152133942,10.021998345851898,10.818393790721894,11.623589448134105,12.42331907749176,13.217750747998556,14.015310768286387,14.816176462173463,15.61056809425354,16.4088530143102,17.21101975440979,18.04278423388799
cummulative feedback,0.0,363.0,698.0,911.0,1061.0,1150.0,1233.0,1271.0,1295.0,1311.0,1320.0,1324.0,1327.0,1336.0,1340.0,1341.0,1341.0,1341.0,1341.0,1341.0,1341.0,1341.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,728.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
