,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,625.0,1624.0,2554.0,3553.0,4552.0,5551.0,6550.0,7549.0,8548.0,9547.0,10546.0,11545.0,12544.0,13543.0,14542.0,15541.0,16540.0,17539.0,18538.0,19537.0,20536.0
Episode reward,0.0,74.16538124407398,-36.4292657702045,65.98611846236957,-35.239273162932086,-31.719194288485436,-35.03767965131496,-33.37160293631105,-33.98098662356502,-34.33390833764265,-32.25211497682488,-35.00791081224046,-32.85839900253056,-31.93271719324101,-30.760583395597166,-31.12229271367239,-33.44778363037283,-30.583457227480853,-32.62968831887708,-31.773961333970327,-32.3031410032571,-31.442957771674372
Episode feedback,0.8,0.49598715811238014,0.3396793583770748,0.26803013964689976,0.14028056098168282,0.12725450889052656,0.07214428850486544,0.050100200350601004,0.0200400801402404,0.02304609216127646,0.0100200400701202,0.00400801602804808,0.00801603205609616,0.0030060120210360602,0.00200400801402404,0.0,0.0,0.0,0.0,0.0,0.0,0.0
total seconds,0.0,47.453760623931885,113.72133803367615,170.9411952495575,225.4223392009735,278.80499172210693,329.9329903125763,380.3357141017914,429.03721141815186,477.75885915756226,525.6683921813965,573.7385349273682,621.5035755634308,668.6597828865051,716.2464828491211,766.3526458740234,815.3803255558014,863.2818439006805,911.0938546657562,958.9718282222748,1006.7736990451813,1054.6015923023224
total minutes,0.0,0.7908960103988647,1.8953556338946025,2.8490199208259583,3.757038986682892,4.646749862035116,5.498883171876272,6.3389285683631895,7.150620190302531,7.962647652626037,8.761139869689941,9.562308915456136,10.35839292605718,11.144329714775086,11.937441380818685,12.77254409790039,13.58967209259669,14.38803073167801,15.184897577762603,15.98286380370458,16.77956165075302,17.576693205038705
cummulative feedback,0.0,309.0,648.0,897.0,1037.0,1164.0,1236.0,1286.0,1306.0,1329.0,1339.0,1343.0,1351.0,1354.0,1356.0,1356.0,1356.0,1356.0,1356.0,1356.0,1356.0,1356.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,623.0,998.0,929.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
