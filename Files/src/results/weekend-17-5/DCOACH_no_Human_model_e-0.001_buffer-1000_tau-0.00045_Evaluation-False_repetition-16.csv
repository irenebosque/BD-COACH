,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,1000.0,1999.0,2998.0,3997.0,4996.0,5720.0,6719.0,7718.0,8717.0,9716.0,10715.0,11714.0,12713.0,13712.0,14711.0,15710.0,16709.0,17708.0,18707.0,19706.0,20705.0
Episode reward,0.0,-52.250288692582906,-49.17108389523729,-51.39234413842525,-46.66178934965653,-47.184581696618956,66.20858165506016,-45.25565096307723,-46.234350342142825,-44.76325712464788,-45.72509724800538,-46.037780990615715,-45.36824801164153,-45.848390926349445,-45.421744223673535,-48.361201137849285,-44.72490244230876,-46.922120326075984,-47.444798885658486,-44.80868383557583,-46.581913484511595,-46.69670984963397
Episode feedback,0.8,0.3296593183069546,0.2575150298020891,0.12124248484845443,0.14929859704479098,0.08116232456797362,0.06777316726449077,0.048096192336576964,0.03106212421737262,0.02104208414725242,0.00400801602804808,0.0030060120210360602,0.0050100200350601,0.00100200400701202,0.00100200400701202,0.00200400801402404,0.0,0.0,0.0,0.0,0.0,0.0
total seconds,0.0,62.24694895744324,122.39815497398376,175.78931403160095,230.21596121788025,281.49176692962646,318.9016876220703,369.019464969635,418.38348603248596,466.90458583831787,514.8834698200226,562.6740734577179,610.59201836586,658.543069601059,707.5499362945557,755.5322453975677,803.9584271907806,851.9989240169525,901.2665059566498,949.9955472946167,997.7207310199738,1045.4108276367188
total minutes,0.0,1.0374491492907205,2.039969249566396,2.9298219005266826,3.836932686964671,4.691529448827108,5.3150281270345054,6.150324416160584,6.973058100541433,7.781743097305298,8.581391163667043,9.377901224295298,10.176533639431,10.975717826684315,11.792498938242595,12.592204089959463,13.399307119846345,14.19998206694921,15.021108432610829,15.833259121576946,16.628678850332896,17.42351379394531
cummulative feedback,0.0,329.0,586.0,707.0,856.0,937.0,986.0,1034.0,1065.0,1086.0,1090.0,1093.0,1098.0,1099.0,1100.0,1102.0,1102.0,1102.0,1102.0,1102.0,1102.0,1102.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,998.0,998.0,998.0,998.0,998.0,723.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
