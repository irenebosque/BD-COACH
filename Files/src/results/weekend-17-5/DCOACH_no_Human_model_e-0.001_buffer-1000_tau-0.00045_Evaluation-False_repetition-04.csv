,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,1000.0,1999.0,2974.0,3825.0,4681.0,5680.0,6679.0,7678.0,8677.0,9676.0,10675.0,11674.0,12673.0,13672.0,14671.0,15670.0,16669.0,17668.0,18667.0,19666.0,20665.0
Episode reward,0.0,-68.34420619764123,-50.65408178556945,49.2589317743616,56.97946458775624,59.448810988960055,-44.74708381611563,-43.279131713543975,-44.14257511885844,-41.827981231038365,-42.64933811565488,-42.6853728090492,-44.1498293674825,-42.538544962018236,-43.66322374328737,-42.709620864060156,-45.504401270614714,-43.69985011047249,-43.37294912382137,-45.07190571135636,-44.074064351215085,-43.06378165175614
Episode feedback,0.8,0.0100200400701202,0.3126252501877502,0.20841889095644878,0.12352941161937717,0.09473684199445984,0.05110220435761302,0.052104208364625045,0.03106212421737262,0.012024048084144241,0.012024048084144241,0.00801603205609616,0.0100200400701202,0.00400801602804808,0.00200400801402404,0.0,0.00100200400701202,0.0,0.0,0.0,0.0,0.0
total seconds,0.0,44.43677043914795,108.13981223106384,165.6835536956787,211.6672739982605,256.585812330246,306.62526512145996,356.50090980529785,405.7527952194214,454.1161184310913,503.5627760887146,552.2665169239044,600.925035238266,648.8511416912079,696.5409896373749,744.4177026748657,792.2855069637299,839.6970314979553,887.5144448280334,935.246499300003,983.4361433982849,1031.2950625419617
total minutes,0.0,0.7406128406524658,1.802330203851064,2.7613925615946453,3.5277878999710084,4.2764302055040995,5.110421085357666,5.941681830088298,6.762546586990356,7.568601973851522,8.39271293481191,9.20444194873174,10.0154172539711,10.814185694853466,11.609016493956249,12.406961711247762,13.204758449395497,13.994950524965923,14.791907413800557,15.58744165500005,16.390602389971416,17.188251042366026
cummulative feedback,0.0,10.0,322.0,525.0,630.0,711.0,762.0,814.0,845.0,857.0,869.0,877.0,887.0,891.0,893.0,893.0,894.0,894.0,894.0,894.0,894.0,894.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,998.0,998.0,974.0,850.0,855.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
