,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,1000.0,1701.0,2700.0,3699.0,4698.0,5697.0,6696.0,7695.0,8694.0,9693.0,10692.0,11691.0,12690.0,13689.0,14688.0,15687.0,16686.0,17685.0,18684.0,19683.0,20682.0
Episode reward,0.0,-50.71149727035311,64.27199472117587,-43.791485813522094,-39.16413495116051,-38.43416445664637,-35.20540966095956,-36.64508087538167,-38.17859645486262,-36.00841278074776,-39.84637027606552,-35.47401595596615,-37.435275456153384,-37.08660408895647,-36.4014865152586,-36.39330771857162,-38.47236581116789,-38.856170636666626,-37.25009833107258,-36.92312786035745,-36.43483527047559,-38.295407333728384
Episode feedback,0.8,0.27254508990726944,0.30142857099795917,0.15230460906582705,0.15931863711491118,0.1152304608063823,0.07014028049084141,0.04709418832956494,0.01903807613322838,0.01603206411219232,0.01903807613322838,0.0060120240420721205,0.00400801602804808,0.0030060120210360602,0.00400801602804808,0.0,0.00100200400701202,0.00100200400701202,0.0,0.0,0.0,0.0
total seconds,0.0,62.92154669761658,116.35293507575989,181.9000928401947,250.3980028629303,311.7971878051758,368.08673334121704,421.2355532646179,471.74419379234314,522.0812110900879,572.10533618927,621.3299252986908,670.789116859436,719.8551988601685,768.7071788311005,817.3365161418915,866.3624167442322,915.0386695861816,963.6177852153778,1012.6590254306793,1061.3913819789886,1110.6128630638123
total minutes,0.0,1.0486924449602764,1.9392155845959982,3.031668214003245,4.173300047715505,5.1966197967529295,6.134778889020284,7.020592554410299,7.862403229872386,8.701353518168132,9.535088936487833,10.35549875497818,11.179818614323933,11.997586647669474,12.811786313851675,13.622275269031524,14.43937361240387,15.250644493103028,16.060296420256297,16.877650423844656,17.689856366316477,18.51021438439687
cummulative feedback,0.0,272.0,483.0,635.0,794.0,909.0,979.0,1026.0,1045.0,1061.0,1080.0,1086.0,1090.0,1093.0,1097.0,1097.0,1098.0,1099.0,1099.0,1099.0,1099.0,1099.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,998.0,700.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
