,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,1000.0,1999.0,2989.0,3988.0,4987.0,5986.0,6985.0,7984.0,8983.0,9982.0,10981.0,11980.0,12979.0,13978.0,14977.0,15976.0,16975.0,17974.0,18973.0,19972.0,20971.0
Episode reward,0.0,-66.96573318594533,-69.63028181198663,54.15083131885695,-41.04998930719635,-41.11334521883583,-41.348401225308535,-40.389958579445555,-40.469381341703105,-41.90475624328803,-41.357158749670575,-40.113176780697025,-42.76726746130037,-41.72903896629761,-42.510421110445854,-40.19693984893712,-41.47528045105495,-38.910157464312896,-39.39783931501931,-41.14396963249688,-40.42610483847799,-40.71464139578681
Episode feedback,0.8,0.0100200400701202,0.00400801602804808,0.22345803819670573,0.17635270523411553,0.07915831655394959,0.052104208364625045,0.0450901803155409,0.027054108189324542,0.014028056098168281,0.01102204407713222,0.00200400801402404,0.00400801602804808,0.00200400801402404,0.00100200400701202,0.00100200400701202,0.0,0.0,0.00100200400701202,0.0,0.00100200400701202,0.0
total seconds,0.0,46.113609313964844,93.1452968120575,156.5569884777069,216.57247924804688,270.2704951763153,322.6486306190491,374.0110511779785,424.53148913383484,474.5021376609802,524.2214703559875,573.2576560974121,622.5746626853943,671.6397271156311,721.217221736908,773.1711027622223,823.3877758979797,873.597715139389,922.933661699295,972.9929203987122,1022.4915461540222,1071.8740239143372
total minutes,0.0,0.7685601552327473,1.5524216135342916,2.609283141295115,3.609541320800781,4.504508252938589,5.377477176984152,6.233517519632975,7.0755248188972475,7.908368961016337,8.737024505933126,9.554294268290201,10.376244378089904,11.193995451927185,12.020287028948466,12.886185046037038,13.723129598299662,14.559961918989817,15.38222769498825,16.21654867331187,17.041525769233704,17.86456706523895
cummulative feedback,0.0,10.0,14.0,235.0,411.0,490.0,542.0,587.0,614.0,628.0,639.0,641.0,645.0,647.0,648.0,649.0,649.0,649.0,650.0,650.0,651.0,651.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,998.0,998.0,989.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
