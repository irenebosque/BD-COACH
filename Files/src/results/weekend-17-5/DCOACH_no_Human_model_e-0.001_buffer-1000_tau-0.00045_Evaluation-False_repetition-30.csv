,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,1000.0,1999.0,2998.0,3997.0,4996.0,5995.0,6994.0,7993.0,8992.0,9991.0,10990.0,11989.0,12988.0,13987.0,14986.0,15985.0,16984.0,17983.0,18982.0,19981.0,20980.0
Episode reward,0.0,-67.85795537145216,-69.59125701314382,-42.05473384724738,-42.19886801585157,-40.19273728912042,-40.69969826253671,-38.97165364269465,-37.88720558012549,-37.81054962827285,-39.62046815157167,-38.557596789735435,-38.82297631959807,-36.909317993669,-39.504027642318604,-39.123570086686684,-40.77147628569446,-38.98526911389398,-39.218103067302735,-39.8364638061755,-39.65988136504209,-38.13585906814259
Episode feedback,0.8,0.00801603205609616,0.00400801602804808,0.2555110217880651,0.11623246481339432,0.08817635261705777,0.054108216378649085,0.048096192336576964,0.027054108189324542,0.01603206411219232,0.0050100200350601,0.0060120240420721205,0.00200400801402404,0.0030060120210360602,0.0050100200350601,0.00100200400701202,0.00200400801402404,0.00200400801402404,0.0,0.0,0.0,0.0
total seconds,0.0,45.855751276016235,92.7589373588562,157.8713572025299,214.01362252235413,267.9164938926697,320.56880593299866,372.99337553977966,423.6474142074585,474.2490584850311,524.4516971111298,575.569905757904,626.1400082111359,675.9716548919678,725.7166516780853,774.8748896121979,824.236095905304,873.4266810417175,922.297073841095,971.2779726982117,1020.4110782146454,1069.6755192279816
total minutes,0.0,0.7642625212669373,1.54598228931427,2.631189286708832,3.5668937087059023,4.465274898211161,5.342813432216644,6.216556258996328,7.060790236790975,7.904150974750519,8.74086161851883,9.592831762631734,10.43566680351893,11.266194248199463,12.095277527968088,12.914581493536632,13.7372682650884,14.557111350695292,15.371617897351582,16.187966211636862,17.006851303577424,17.82792532046636
cummulative feedback,0.0,8.0,12.0,267.0,383.0,471.0,525.0,573.0,600.0,616.0,621.0,627.0,629.0,632.0,637.0,638.0,640.0,642.0,642.0,642.0,642.0,642.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
