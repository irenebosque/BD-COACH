,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,1000.0,1999.0,2998.0,3997.0,4996.0,5995.0,6994.0,7993.0,8992.0,9991.0,10990.0,11989.0,12988.0,13987.0,14986.0,15985.0,16984.0,17983.0,18982.0,19981.0,20980.0
Episode reward,0.0,-64.58802548478658,-54.07252241402539,-49.955575666910946,-48.28294427998934,-47.55755081695344,-47.668384356565504,-46.612227530631394,-46.5353884636307,-46.78363145696554,-44.771819786800805,-45.61359344843768,-46.54893112774521,-46.9644942399875,-46.901996202230734,-47.05889742063956,-47.18480063612517,-47.98015091652787,-47.895543524816176,-47.54842081015351,-47.16823451725393,-45.09388560723914
Episode feedback,0.8,0.01102204407713222,0.23847695366886076,0.20741482945148815,0.150300601051803,0.09118236463809383,0.033066132231396664,0.04108216428749282,0.028056112196336563,0.014028056098168281,0.01603206411219232,0.00400801602804808,0.0050100200350601,0.00100200400701202,0.0030060120210360602,0.0,0.0,0.0030060120210360602,0.0,0.0,0.00100200400701202,0.0
total seconds,0.0,46.09643483161926,112.46075177192688,174.75950241088867,232.35466861724854,286.5635254383087,337.4262945652008,388.758841753006,439.3916873931885,489.22637581825256,539.18310379982,588.3402903079987,638.1818664073944,688.9803411960602,739.6097891330719,789.1933972835541,838.309531211853,887.5093665122986,936.3123269081116,985.4505345821381,1033.9186038970947,1082.943103313446
total minutes,0.0,0.7682739138603211,1.874345862865448,2.912658373514811,3.8725778102874755,4.776058757305146,5.62377157608668,6.479314029216766,7.323194789886474,8.153772930304209,8.986385063330333,9.805671505133311,10.63636444012324,11.483005686601002,12.326829818884532,13.153223288059234,13.97182552019755,14.791822775204976,15.605205448468526,16.424175576368967,17.231976731618246,18.049051721890766
cummulative feedback,0.0,11.0,249.0,456.0,606.0,697.0,730.0,771.0,799.0,813.0,829.0,833.0,838.0,839.0,842.0,842.0,842.0,845.0,845.0,845.0,846.0,846.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
