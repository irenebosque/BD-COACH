,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31
Accumulated time steps,0.0,1000.0,1663.0,2662.0,3049.0,4048.0,4916.0,5915.0,6914.0,7913.0,8807.0,9806.0,10383.0,10757.0,11504.0,11994.0,12993.0,13359.0,13625.0,14260.0,14552.0,14826.0,15725.0,16218.0,16493.0,16969.0,17524.0,17887.0,18259.0,18729.0,19010.0,19707.0
Episode reward,0.0,-61.123645899697934,61.725152858282655,-65.72771432524814,82.17588489382713,-69.51137888529757,54.36490882150279,-65.26696125246778,-62.557229691252964,-55.92715323318971,45.80431122272844,-61.31377976323148,65.71826097074481,84.06536416141878,61.8429045212471,77.9904646862351,-49.90343578032428,79.92222675063951,85.426236900063,64.90896918143648,82.61068045408484,84.13877968902565,60.217066185054314,71.38513831642305,84.55471135588,73.1231520839159,68.98289442452766,80.26647142655612,79.33048823828642,73.74535256361679,83.7811035325777,59.03528090361066
Episode feedback,0.8,0.25150300576001705,0.21752265828168782,0.01603206411219232,0.13730569912615104,0.0100200400701202,0.06459054202469372,0.01703406811920434,0.00801603205609616,0.012024048084144241,0.008958566619307317,0.0060120240420721205,0.003472222216194059,0.002680965140265509,0.001340482571929648,0.004089979541738283,0.00100200400701202,0.0,0.0,0.0,0.0,0.0036630036495860674,0.0011135857448623767,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
total seconds,0.0,70.70185327529907,116.36572170257568,164.6721088886261,188.12697291374207,237.9400360584259,287.0890393257141,335.1115999221802,383.57010769844055,431.89108204841614,475.31053400039673,522.8843474388123,551.7625567913055,570.4675874710083,607.901469707489,632.2986521720886,682.2266774177551,701.2864291667938,715.1414039134979,746.2494878768921,761.741489648819,776.3085405826569,821.2282862663269,845.8149621486664,860.2577664852142,884.5971691608429,911.5735626220703,929.3934988975525,947.4709525108337,969.7923152446747,983.8426818847656,1017.2686586380005
total minutes,0.0,1.1783642212549845,1.939428695042928,2.7445351481437683,3.135449548562368,3.965667267640432,4.784817322095235,5.5851933320363365,6.392835128307342,7.1981847008069355,7.921842233339945,8.714739123980204,9.196042613188427,9.507793124516805,10.131691161791483,10.53831086953481,11.370444623629252,11.688107152779898,11.919023398558299,12.437491464614869,12.695691494146983,12.938475676377614,13.687138104438782,14.096916035811107,14.337629441420237,14.743286152680716,15.192892710367838,15.489891648292542,15.79118254184723,16.163205254077912,16.39737803141276,16.954477643966676
cummulative feedback,0.0,251.0,395.0,411.0,464.0,474.0,530.0,547.0,555.0,567.0,575.0,581.0,583.0,584.0,585.0,587.0,588.0,588.0,588.0,588.0,588.0,589.0,590.0,590.0,590.0,590.0,590.0,590.0,590.0,590.0,590.0,590.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,998.0,662.0,998.0,386.0,998.0,867.0,998.0,998.0,998.0,893.0,998.0,576.0,373.0,746.0,489.0,998.0,365.0,265.0,634.0,291.0,273.0,898.0,492.0,274.0,475.0,554.0,362.0,371.0,469.0,280.0,696.0
e,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
