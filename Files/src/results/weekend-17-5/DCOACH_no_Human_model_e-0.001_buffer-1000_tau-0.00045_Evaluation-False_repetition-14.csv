,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,660.0,1659.0,2658.0,3657.0,4656.0,5655.0,6654.0,7653.0,8652.0,9651.0,10650.0,11649.0,12648.0,13647.0,14646.0,15645.0,16644.0,17643.0,18642.0,19641.0,20640.0
Episode reward,0.0,71.96101168829348,-35.21888924625776,-37.26716109388913,-33.225482262643624,-32.24627569499122,-31.068573208824525,-31.222668799885493,-32.01097233024873,-32.66746158159323,-31.25399383231558,-32.17105971413085,-32.10435782339151,-32.153759842392574,-33.17044953565827,-33.355037093385,-32.61229856029873,-32.2857714986994,-33.39660328368406,-32.668760698396746,-31.743065674596423,-32.99225611187562
Episode feedback,0.8,0.4848024308741604,0.29759519008256996,0.20340681342344008,0.16432865714997127,0.09318637265211786,0.07915831655394959,0.05110220435761302,0.033066132231396664,0.01603206411219232,0.013026052091156261,0.007014028049084141,0.0050100200350601,0.00400801602804808,0.0030060120210360602,0.0030060120210360602,0.0,0.0,0.0,0.0,0.0,0.0
total seconds,0.0,46.12785601615906,108.55449342727661,166.04713702201843,221.4354863166809,273.464786529541,324.86786818504333,375.0413408279419,424.6877472400665,473.6670413017273,523.586268901825,572.2788398265839,620.5163931846619,668.4395380020142,715.980400800705,763.80557513237,811.0103540420532,858.7729749679565,906.3689765930176,954.5683588981628,1002.5460705757141,1050.2343862056732
total minutes,0.0,0.7687976002693176,1.8092415571212768,2.7674522837003073,3.6905914386113485,4.557746442159017,5.4144644697507225,6.250689013799032,7.078129120667776,7.894450688362122,8.726437815030415,9.537980663776398,10.341939886411032,11.140658966700236,11.933006680011749,12.730092918872833,13.51683923403422,14.31288291613261,15.106149609883627,15.909472648302714,16.709101176261903,17.50390643676122
cummulative feedback,0.0,319.0,616.0,819.0,983.0,1076.0,1155.0,1206.0,1239.0,1255.0,1268.0,1275.0,1280.0,1284.0,1287.0,1290.0,1290.0,1290.0,1290.0,1290.0,1290.0,1290.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,658.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
