,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,1000.0,1888.0,2887.0,3886.0,4885.0,5884.0,6883.0,7882.0,8881.0,9880.0,10879.0,11878.0,12877.0,13876.0,14875.0,15874.0,16873.0,17872.0,18871.0,19870.0,20869.0
Episode reward,0.0,-67.33579993562833,61.23182271489349,-40.055706245940925,-38.83778326607075,-37.999960193882075,-37.713340023857036,-37.14496046690192,-37.50133852267446,-38.12964679809731,-37.90884497677514,-37.49364071348904,-38.18434477032546,-37.78613574116645,-38.547449743088535,-37.90685272233427,-38.42097456872797,-37.982856557623386,-38.845821568056515,-37.34421308237127,-36.92136037133401,-37.80022990527456
Episode feedback,0.8,0.012024048084144241,0.36527621153858375,0.1943887773603319,0.1152304608063823,0.13126252491857462,0.06913827648382938,0.04709418832956494,0.02304609216127646,0.013026052091156261,0.013026052091156261,0.00400801602804808,0.0050100200350601,0.00200400801402404,0.00100200400701202,0.00100200400701202,0.00100200400701202,0.0,0.0,0.0,0.0,0.0
total seconds,0.0,46.45364832878113,116.03638625144958,180.52946543693542,238.2357542514801,295.64189553260803,348.3554117679596,399.9653379917145,449.833833694458,499.7886128425598,549.0845527648926,598.5863461494446,647.8243181705475,696.7602751255035,746.5225732326508,795.3441140651703,844.3890330791473,893.562385559082,942.7607095241547,992.2018682956696,1041.7473208904266,1094.2758874893188
total minutes,0.0,0.7742274721463521,1.933939770857493,3.0088244239489237,3.970595904191335,4.9273649255434675,5.805923529465994,6.666088966528575,7.4972305615743,8.329810214042663,9.15140921274821,9.976439102490742,10.797071969509124,11.612671252091726,12.442042887210846,13.255735234419506,14.073150551319122,14.8927064259847,15.712678492069244,16.536697804927826,17.36245534817378,18.237931458155312
cummulative feedback,0.0,12.0,336.0,530.0,645.0,776.0,845.0,892.0,915.0,928.0,941.0,945.0,950.0,952.0,953.0,954.0,955.0,955.0,955.0,955.0,955.0,955.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,998.0,887.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
