,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30
Accumulated time steps,0.0,843.0,1093.0,1457.0,2142.0,2409.0,2708.0,2960.0,3323.0,3658.0,3996.0,4995.0,5811.0,6371.0,7370.0,7920.0,8421.0,9414.0,10064.0,10860.0,11337.0,11811.0,12810.0,13809.0,14734.0,15733.0,16685.0,17684.0,18233.0,19232.0,20231.0
Episode reward,0.0,54.29392488522282,86.43676496050284,79.87881739967025,66.94126332144563,87.48181465887764,85.05298513655676,88.35877404540088,81.84409954149255,83.89284339150743,82.52287763613923,-45.22935189646291,63.9151795827961,76.13937650060471,-42.21206323286044,74.54890121615587,80.03114635910114,57.06734729961064,73.43642111737063,69.36934433497748,80.53446800809607,79.58072114019208,-36.81734772888046,-41.86560416245769,61.13719693603598,-37.577560442856246,60.655795467278935,-39.29043995904658,78.12851759420894,-37.001850031258186,-41.76897980070422
Episode feedback,0.8,0.4126040423155719,0.389558231367236,0.2506887045435573,0.2266081868032044,0.16541353321273108,0.11073825466195217,0.12350597560356186,0.0994475135374378,0.09281437097959769,0.09198813029083641,0.07014028049084141,0.05276073613158192,0.0500894453486772,0.024048096168288482,0.02550091070036264,0.013999999972,0.01612903224180541,0.015408320469324622,0.00754716980182746,0.0,0.006342494701178658,0.00200400801402404,0.00801603205609616,0.00216450216215963,0.00100200400701202,0.0,0.0,0.0,0.0,0.0
total seconds,0.0,56.02001070976257,73.5085997581482,95.79145240783691,135.94835686683655,151.7812943458557,168.478013753891,182.91937279701233,202.70401883125305,221.05602741241455,239.3779902458191,290.62163186073303,331.44565176963806,359.9842224121094,408.86555457115173,436.2047584056854,461.0257713794708,509.49164152145386,541.2013454437256,580.0830795764923,603.1402289867401,626.3469567298889,674.0367164611816,722.3706312179565,767.2707929611206,815.5018429756165,861.1571869850159,908.8543400764465,935.5742506980896,983.5325481891632,1031.6109924316406
total minutes,0.0,0.9336668451627096,1.2251433293024698,1.5965242067972818,2.265805947780609,2.529688239097595,2.807966895898183,3.0486562132835386,3.3784003138542174,3.6842671235402427,3.9896331707636516,4.843693864345551,5.524094196160634,5.999737040201823,6.814425909519196,7.270079306761423,7.683762856324514,8.491527358690897,9.020022424062093,9.668051326274872,10.052337149779001,10.439115945498148,11.233945274353028,12.039510520299276,12.78784654935201,13.591697382926942,14.352619783083599,15.147572334607442,15.592904178301493,16.392209136486052,17.193516540527344
cummulative feedback,0.0,347.0,444.0,535.0,690.0,734.0,767.0,798.0,834.0,865.0,896.0,966.0,1009.0,1037.0,1061.0,1075.0,1082.0,1098.0,1108.0,1114.0,1114.0,1117.0,1119.0,1127.0,1129.0,1130.0,1130.0,1130.0,1130.0,1130.0,1130.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,841.0,249.0,363.0,684.0,266.0,298.0,251.0,362.0,334.0,337.0,998.0,815.0,559.0,998.0,549.0,500.0,992.0,649.0,795.0,476.0,473.0,998.0,998.0,924.0,998.0,951.0,998.0,548.0,998.0,998.0
e,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
