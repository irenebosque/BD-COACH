,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30
Accumulated time steps,0.0,712.0,958.0,1228.0,1582.0,2026.0,2491.0,2941.0,3940.0,4403.0,4927.0,5884.0,6304.0,7257.0,7914.0,8482.0,9129.0,10103.0,10661.0,11222.0,11949.0,12427.0,13407.0,14158.0,15023.0,15820.0,16819.0,17818.0,18817.0,19816.0,20815.0
Episode reward,0.0,67.36119574746778,87.60243294562862,86.15997514312848,83.80421762342084,79.85404995182863,78.2732237099763,80.84503684446665,-38.00698213108213,79.11093963647491,76.62494564261104,61.01906341535002,84.6026579902945,64.42023970886731,74.2815506728089,78.3444526949927,77.21934320792624,64.02777528626505,81.6431315990078,80.3298673141519,72.91842547640982,82.84581624360217,65.21124527316135,73.62984691375102,68.61839238859473,71.54384880942214,-35.661238023179536,-34.87046778522176,-36.6721693167101,-36.177745767750444,-33.213568596265
Episode feedback,0.8,0.45352112612180123,0.29387754982090797,0.24163568683406808,0.2549575063598937,0.23702031549205346,0.22413793055142686,0.19376391939028081,0.12625250488351453,0.11904761878994022,0.08221797307415302,0.060669456003483835,0.04295942710510876,0.032563025175879175,0.025914634106837448,0.021164021126694847,0.01702786375073086,0.011305241509449906,0.001795332133222025,0.0035714285650510205,0.004132231399266899,0.004192872108610331,0.0020429009172186915,0.0,0.002314814812135631,0.0,0.0,0.0,0.0,0.00100200400701202,0.0
total seconds,0.0,54.97318243980408,72.78228998184204,90.98341131210327,114.38998436927795,143.13668584823608,172.8685896396637,199.97918677330017,256.2918803691864,282.26441073417664,310.8038430213928,360.5064537525177,382.5015938282013,431.14131903648376,464.61953473091125,493.7616038322449,526.3357300758362,574.8960793018341,603.3851563930511,632.4713521003723,669.4080109596252,694.320216178894,742.9684886932373,779.9427168369293,822.6533086299896,862.3141891956329,911.0286829471588,959.5931754112244,1008.8524429798126,1058.1056735515594,1107.0652289390564
total minutes,0.0,0.916219707330068,1.213038166364034,1.5163901885350546,1.906499739487966,2.3856114308039347,2.8811431606610616,3.3329864462216694,4.27153133948644,4.70440684556961,5.180064050356547,6.008440895875295,6.375026563803355,7.185688650608062,7.743658912181854,8.229360063870748,8.772262167930602,9.581601321697235,10.05641927321752,10.541189201672871,11.15680018266042,11.572003602981567,12.382808144887289,12.999045280615489,13.710888477166494,14.371903153260549,15.183811382452648,15.993219590187072,16.814207382996877,17.63509455919266,18.451087148984275
cummulative feedback,0.0,322.0,394.0,459.0,549.0,654.0,758.0,845.0,971.0,1026.0,1069.0,1127.0,1145.0,1176.0,1193.0,1205.0,1216.0,1227.0,1228.0,1230.0,1233.0,1235.0,1237.0,1237.0,1239.0,1239.0,1239.0,1239.0,1239.0,1240.0,1240.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,710.0,245.0,269.0,353.0,443.0,464.0,449.0,998.0,462.0,523.0,956.0,419.0,952.0,656.0,567.0,646.0,973.0,557.0,560.0,726.0,477.0,979.0,750.0,864.0,796.0,998.0,998.0,998.0,998.0,998.0
e,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
