,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,519.0,985.0,1471.0,2412.0,3411.0,4410.0,5409.0,6408.0,7407.0,8406.0,9405.0,10404.0,11403.0,12402.0,13401.0,14400.0,15399.0,16398.0,17397.0,18396.0,19395.0
Episode reward,0.0,73.21255233424534,75.76622546426789,76.95754190619317,55.69918940405867,-53.10372988960287,-64.23709385856871,-48.39242078563861,-63.36014197513176,-54.90857424222025,-63.51301108606087,-57.212160258659004,-59.190630499776276,-47.916421919553926,-60.23942447163988,-61.29690208845563,-53.214546616333415,-62.20334723817533,-57.874851331602315,-57.45432297096142,-61.21492592217227,-58.9302192015949
Episode feedback,0.8,0.49516440910026227,0.255913977944271,0.19793814392177703,0.16808510620416478,0.09619238467315393,0.0050100200350601,0.06212424843474524,0.01102204407713222,0.026052104182312522,0.01102204407713222,0.00901803606310818,0.0030060120210360602,0.0030060120210360602,0.0,0.00100200400701202,0.00100200400701202,0.0,0.0,0.0,0.0,0.0
total seconds,0.0,34.73140239715576,62.53703260421753,90.1457109451294,142.5276494026184,194.41225409507751,242.72243213653564,292.58014941215515,339.0603930950165,386.3669719696045,433.8289256095886,482.03059101104736,531.3142228126526,581.1640267372131,630.7872421741486,680.6473767757416,730.3948910236359,780.3987584114075,830.244704246521,879.8561120033264,929.0203521251678,977.9971561431885
total minutes,0.0,0.5788567066192627,1.0422838767369589,1.5024285157521566,2.3754608233769736,3.2402042349179587,4.045373868942261,4.8763358235359195,5.651006551583608,6.439449532826742,7.230482093493143,8.033843183517456,8.855237046877543,9.686067112286885,10.513120702902476,11.34412294626236,12.173248183727264,13.006645973523458,13.837411737442016,14.664268533388773,15.483672535419464,16.299952602386476
cummulative feedback,0.0,256.0,375.0,471.0,629.0,725.0,730.0,792.0,803.0,829.0,840.0,849.0,852.0,855.0,855.0,856.0,857.0,857.0,857.0,857.0,857.0,857.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,517.0,465.0,485.0,940.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
