,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,1000.0,1999.0,2998.0,3997.0,4716.0,5715.0,6714.0,7713.0,8712.0,9711.0,10710.0,11709.0,12708.0,13707.0,14706.0,15705.0,16704.0,17703.0,18702.0,19701.0,20700.0
Episode reward,0.0,-46.147114823403435,-44.15762619251372,-43.09640440231259,-43.55418329801455,70.59701028549038,-40.099801150064636,-40.181745402208094,-38.84692361797808,-41.707278042937354,-42.506776787923016,-42.64797021059676,-41.46301060543568,-42.86638639374527,-42.01694665693124,-41.19963960004017,-39.63294127011953,-43.13934260903071,-40.58822696303627,-42.210972037675596,-41.53797985618446,-42.01869818609108
Episode feedback,0.8,0.46593186326058933,0.28156312597037764,0.19539078136734392,0.14729458903076695,0.11559888563287063,0.06312625244175726,0.050100200350601004,0.024048096168288482,0.027054108189324542,0.00901803606310818,0.00901803606310818,0.0050100200350601,0.00200400801402404,0.0,0.0030060120210360602,0.0,0.0,0.0,0.0,0.0,0.0
total seconds,0.0,69.69878649711609,131.4865427017212,188.98671317100525,244.23754286766052,283.98868775367737,335.7541902065277,387.195613861084,436.6711723804474,485.90123867988586,534.2001388072968,582.1456463336945,629.7860310077667,677.5861260890961,724.9349892139435,772.7967128753662,820.4794051647186,868.1815493106842,916.1833274364471,964.1675465106964,1011.869381904602,1059.6862018108368
total minutes,0.0,1.1616464416186014,2.19144237836202,3.1497785528500875,4.070625714461008,4.7331447958946224,5.595903170108795,6.453260231018066,7.277852873007457,8.098353977998098,8.90333564678828,9.702427438894908,10.496433850129446,11.293102101484935,12.082249820232391,12.879945214589437,13.67465675274531,14.469692488511404,15.269722123940786,16.069459108511605,16.864489698410033,17.66143669684728
cummulative feedback,0.0,465.0,746.0,941.0,1088.0,1171.0,1234.0,1284.0,1308.0,1335.0,1344.0,1353.0,1358.0,1360.0,1360.0,1363.0,1363.0,1363.0,1363.0,1363.0,1363.0,1363.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,998.0,998.0,998.0,998.0,718.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
