,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29
Accumulated time steps,0.0,363.0,859.0,1618.0,2078.0,2704.0,3053.0,3661.0,4032.0,4464.0,5080.0,6079.0,7078.0,7507.0,7822.0,8768.0,9628.0,10359.0,11358.0,12086.0,12696.0,13681.0,14680.0,15592.0,16591.0,17372.0,18371.0,18966.0,19965.0,20964.0
Episode reward,0.0,82.35033671460835,75.70845342177596,65.15632215209567,79.24305292999269,73.10340790495238,85.73827540600578,73.41723037229033,82.31637745609603,80.68631322298435,73.57370011642087,-41.350413089932985,-37.35424505779912,81.55792764519772,86.95123846109496,62.05764380437555,65.95723564943513,70.51280200197945,-39.096112906188466,71.7412058447289,73.20894037043172,60.48728809150644,-41.60187054782752,63.10299779967581,-41.63418580083385,64.03344740508861,-39.263695828281136,73.87464355887599,-41.69437494325802,-40.46515072079882
Episode feedback,0.8,0.3905817163695797,0.3454545447566575,0.286279682999631,0.22222222173807796,0.17119999972608,0.15517241334720572,0.138385502243187,0.12972972937910884,0.08584686755023929,0.09105691042104568,0.03607214425243272,0.04108216428749282,0.04205607466809328,0.025477706925230232,0.01587301585621903,0.005820721762723258,0.009589041082754738,0.00200400801402404,0.0013755158165398682,0.0032840722441969256,0.0020325203231376827,0.00400801602804808,0.0,0.00200400801402404,0.0,0.0,0.0,0.00100200400701202,0.0
total seconds,0.0,23.17219352722168,55.377564430236816,102.50443077087402,130.79683780670166,167.2453978061676,187.48758602142334,222.46725225448608,245.36220598220825,269.57098507881165,303.7967801094055,354.52680826187134,404.73183822631836,426.61992263793945,442.7186646461487,488.79471468925476,530.3291425704956,565.61097407341,613.2842252254486,648.4891474246979,678.2812662124634,725.2845458984375,773.539871931076,817.6098539829254,865.1796209812164,902.5098669528961,950.4266521930695,979.2350265979767,1026.9649527072906,1074.5587430000305
total minutes,0.0,0.3862032254536947,0.9229594071706136,1.708407179514567,2.179947296778361,2.78742329676946,3.1247931003570555,3.707787537574768,4.089370099703471,4.4928497513135275,5.063279668490092,5.908780137697856,6.745530637105306,7.110332043965657,7.3786444107691445,8.146578578154246,8.838819042841594,9.426849567890168,10.221403753757476,10.808152457078299,11.304687770207723,12.088075764973958,12.892331198851268,13.626830899715424,14.419660349686941,15.041831115881601,15.840444203217825,16.320583776632944,17.11608254512151,17.90931238333384
cummulative feedback,0.0,141.0,312.0,529.0,631.0,738.0,792.0,876.0,924.0,961.0,1017.0,1053.0,1094.0,1112.0,1120.0,1135.0,1140.0,1147.0,1149.0,1150.0,1152.0,1154.0,1158.0,1158.0,1160.0,1160.0,1160.0,1160.0,1161.0,1161.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,361.0,495.0,758.0,459.0,625.0,348.0,607.0,370.0,431.0,615.0,998.0,998.0,428.0,314.0,945.0,859.0,730.0,998.0,727.0,609.0,984.0,998.0,911.0,998.0,780.0,998.0,594.0,998.0,998.0
e,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
