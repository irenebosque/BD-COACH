,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30
Accumulated time steps,0.0,547.0,807.0,1155.0,1402.0,1995.0,2611.0,3052.0,4051.0,4491.0,5255.0,5689.0,6138.0,6471.0,7252.0,8012.0,8748.0,9075.0,10056.0,10782.0,11436.0,11826.0,12761.0,13760.0,14759.0,15635.0,16121.0,17120.0,18119.0,19118.0,20064.0
Episode reward,0.0,75.96587086670333,88.17689055058698,85.49164327415541,88.42045884322897,69.1855872343694,70.77593728409084,81.57761250588142,-43.498584690790196,79.56859208067203,67.4734563965707,85.38633047106309,83.66044408381208,86.27446544815005,71.65573422943864,78.10777632059205,75.43992487323187,91.87229056311827,72.75724997066462,77.24352198970536,76.07655496125719,87.99572360560067,71.60126666283419,-35.67459896986,-30.901241959900275,74.7447194451243,87.2061868452634,-25.79578633952028,-33.30122975011117,-33.512710127543755,72.69004151028523
Episode feedback,0.8,0.38899082497432874,0.3899613884557475,0.36599423525650077,0.28861788500561836,0.1638513510745754,0.16910569078194196,0.17727272686983472,0.09619238467315393,0.08428245994468687,0.051114023524096955,0.043879907519907835,0.02901785707808514,0.051204819122877054,0.026923076888560157,0.026350461098352488,0.020408163237539915,0.003067484653167225,0.00918367346001666,0.008275862057550536,0.004594180697405543,0.002570694080795131,0.0021413276208336962,0.00100200400701202,0.00400801602804808,0.0,0.002061855665851844,0.0,0.0,0.0,0.0
total seconds,0.0,38.49692940711975,58.761210203170776,83.80847001075745,100.49231934547424,134.61122059822083,169.97931361198425,195.48044061660767,248.3154435157776,271.535005569458,309.96080017089844,332.1999764442444,354.9724488258362,372.28236865997314,410.6168761253357,447.91645193099976,484.10410261154175,500.4153747558594,547.5404696464539,582.7395379543304,614.4623720645905,633.7122330665588,678.6620197296143,726.2280135154724,773.9916791915894,815.5219869613647,839.0542867183685,886.6916353702545,936.242716550827,985.0132791996002,1030.6943016052246
total minutes,0.0,0.6416154901186625,0.9793535033861797,1.3968078335126242,1.6748719890912374,2.2435203433036803,2.8329885601997375,3.2580073436101276,4.13859072526296,4.525583426157634,5.16601333618164,5.53666627407074,5.916207480430603,6.204706144332886,6.843614602088929,7.465274198849996,8.068401710192363,8.34025624593099,9.125674494107564,9.712325632572174,10.241039534409841,10.561870551109314,11.311033662160238,12.103800225257874,12.899861319859822,13.592033116022746,13.98423811197281,14.778193922837575,15.604045275847117,16.416887986660004,17.178238360087075
cummulative feedback,0.0,212.0,313.0,440.0,511.0,608.0,712.0,790.0,886.0,923.0,962.0,981.0,994.0,1011.0,1032.0,1052.0,1067.0,1068.0,1077.0,1083.0,1086.0,1087.0,1089.0,1090.0,1094.0,1094.0,1095.0,1095.0,1095.0,1095.0,1095.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,545.0,259.0,347.0,246.0,592.0,615.0,440.0,998.0,439.0,763.0,433.0,448.0,332.0,780.0,759.0,735.0,326.0,980.0,725.0,653.0,389.0,934.0,998.0,998.0,875.0,485.0,998.0,998.0,998.0,945.0
e,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
