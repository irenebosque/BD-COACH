,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,1000.0,1999.0,2998.0,3997.0,4996.0,5995.0,6994.0,7993.0,8992.0,9991.0,10990.0,11989.0,12988.0,13987.0,14986.0,15985.0,16984.0,17983.0,18982.0,19981.0,20980.0
Episode reward,0.0,-71.1674282211726,-58.45416446305849,-54.527600188148824,-54.35370181889224,-54.23025958134004,-55.14364022596415,-54.83221633409446,-55.36584444585748,-54.75092278636363,-55.01220946853032,-54.73628638991281,-55.15438209711321,-54.62934175356008,-54.386214355124736,-54.525473912905326,-53.26966032482406,-54.492031218492066,-55.33481377737072,-54.812762694535095,-54.275047125424614,-54.229642961533834
Episode feedback,0.8,0.0100200400701202,0.31663326621579835,0.19138276533929582,0.15130260505881502,0.04709418832956494,0.06613226446279333,0.01903807613322838,0.01903807613322838,0.01603206411219232,0.0060120240420721205,0.012024048084144241,0.00400801602804808,0.0,0.0,0.00200400801402404,0.0,0.00200400801402404,0.0,0.0,0.0,0.0
total seconds,0.0,43.522905588150024,111.60849499702454,177.10646271705627,237.36968541145325,296.0271418094635,359.80912804603577,417.54955673217773,478.20642280578613,535.0542409420013,588.6582698822021,646.7432198524475,714.2433648109436,784.7129657268524,855.8642690181732,926.0544157028198,988.6603198051453,1040.6876151561737,1090.3318040370941,1149.1950616836548,1198.0335757732391,1246.4519996643066
total minutes,0.0,0.7253817598025004,1.8601415832837422,2.9517743786176047,3.956161423524221,4.933785696824391,5.9968188007672625,6.959159278869629,7.970107046763102,8.917570682366689,9.81097116470337,10.779053664207458,11.904056080182393,13.078549428780873,14.26440448363622,15.434240261713663,16.47767199675242,17.344793585936227,18.17219673395157,19.153251028060915,19.96722626288732,20.774199994405112
cummulative feedback,0.0,10.0,326.0,517.0,668.0,715.0,781.0,800.0,819.0,835.0,841.0,853.0,857.0,857.0,857.0,859.0,859.0,861.0,861.0,861.0,861.0,861.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
