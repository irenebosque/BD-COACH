,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,1000.0,1999.0,2998.0,3997.0,4996.0,5995.0,6994.0,7993.0,8992.0,9991.0,10990.0,11989.0,12988.0,13987.0,14986.0,15985.0,16984.0,17983.0,18982.0,19981.0,20980.0
Episode reward,0.0,-65.43285499851687,-69.16844758458338,-50.01585441780783,-48.813769046085774,-46.37583398744606,-46.68358491122417,-46.29898751029526,-46.530496238845664,-46.63888903512011,-46.674604529815554,-46.49820844415463,-46.28811490381463,-47.25665291754935,-45.26328792227739,-47.080007203971824,-46.096469226808395,-45.10043642502175,-47.306308720332446,-46.314985925296526,-48.17063836433447,-46.573790944279935
Episode feedback,0.8,0.007014028049084141,0.00801603205609616,0.1793587172551516,0.10621242474327412,0.0651302604557813,0.06412825644876928,0.027054108189324542,0.01803607212621636,0.00901803606310818,0.0060120240420721205,0.00901803606310818,0.0050100200350601,0.0030060120210360602,0.0,0.0,0.00100200400701202,0.0,0.0,0.00100200400701202,0.0,0.0
total seconds,0.0,44.71643137931824,91.95647096633911,157.11944675445557,217.6537733078003,273.83100628852844,326.4561424255371,375.9190249443054,424.70034646987915,472.8218333721161,520.7081291675568,568.941743850708,616.7609984874725,664.5768041610718,712.4040429592133,760.3375189304352,807.69065284729,855.9036128520966,903.2675127983093,951.0629816055298,998.6343605518341,1046.528439283371
total minutes,0.0,0.7452738563219706,1.5326078494389852,2.618657445907593,3.627562888463338,4.563850104808807,5.440935707092285,6.26531708240509,7.07833910783132,7.880363889535269,8.67846881945928,9.4823623975118,10.27934997479121,11.076280069351196,11.873400715986888,12.67229198217392,13.461510880788166,14.26506021420161,15.05445854663849,15.851049693425496,16.643906009197234,17.44214065472285
cummulative feedback,0.0,7.0,15.0,194.0,300.0,365.0,429.0,456.0,474.0,483.0,489.0,498.0,503.0,506.0,506.0,506.0,507.0,507.0,507.0,508.0,508.0,508.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
