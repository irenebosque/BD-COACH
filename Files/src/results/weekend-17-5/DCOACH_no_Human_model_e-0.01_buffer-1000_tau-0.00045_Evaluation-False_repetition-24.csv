,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,449.0,1448.0,2447.0,3446.0,4445.0,5444.0,6378.0,7325.0,8324.0,9323.0,10322.0,11321.0,12320.0,13319.0,14318.0,15317.0,16316.0,17315.0,18314.0,19313.0,20312.0
Episode reward,0.0,76.95796456373422,-39.81632755523438,-37.966199783976826,-36.18941424623631,-35.5508565927401,-33.85102005636959,64.64549919951241,62.370812598373995,-34.43787203524322,-35.11287630470261,-36.69585692643488,-36.84178908691486,-37.24239170340413,-36.50527869723108,-35.89304862650454,-36.732330580202785,-35.77522425047343,-36.95057809572656,-36.3522525158852,-36.51442035873628,-37.98619655937925
Episode feedback,0.8,0.4272930639210446,0.35170340646121906,0.23246492962678864,0.17134268519905543,0.1152304608063823,0.07214428850486544,0.0632368702430473,0.03699788579598532,0.02204408815426444,0.01803607212621636,0.00801603205609616,0.00400801602804808,0.00100200400701202,0.0030060120210360602,0.0,0.00100200400701202,0.0,0.00100200400701202,0.0,0.0,0.0
total seconds,0.0,33.279372453689575,107.37998032569885,171.0822594165802,229.18137502670288,283.69220185279846,335.88185596466064,384.6036229133606,432.9588050842285,482.7867593765259,533.0196692943573,582.2507600784302,631.2838776111603,680.1117660999298,729.2291581630707,779.3981063365936,833.2961506843567,884.5927069187164,935.0354285240173,984.3941764831543,1033.3653054237366,1083.5259699821472
total minutes,0.0,0.5546562075614929,1.7896663387616476,2.8513709902763367,3.8196895837783815,4.728203364213308,5.5980309327443445,6.410060381889343,7.215980084737142,8.046445989608765,8.883661154905955,9.704179334640504,10.521397960186004,11.335196101665497,12.153819302717844,12.989968438943228,13.888269178072612,14.743211781978607,15.583923808733623,16.40656960805257,17.22275509039561,18.05876616636912
cummulative feedback,0.0,191.0,542.0,774.0,945.0,1060.0,1132.0,1191.0,1226.0,1248.0,1266.0,1274.0,1278.0,1279.0,1282.0,1282.0,1283.0,1283.0,1284.0,1284.0,1284.0,1284.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,447.0,998.0,998.0,998.0,998.0,998.0,933.0,946.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
