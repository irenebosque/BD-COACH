,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,1000.0,1970.0,2734.0,3629.0,4628.0,5627.0,6626.0,7625.0,8624.0,9623.0,10622.0,11621.0,12620.0,13619.0,14618.0,15617.0,16616.0,17615.0,18614.0,19613.0,20612.0
Episode reward,0.0,-46.43129336670355,56.92430405344118,69.16081315320562,64.17518641628222,-31.054009129112924,-35.5709778826977,-27.855358239712835,-27.53427441714947,-28.986877362473066,-27.29983437090275,-28.19031562026834,-29.39898747448899,-30.55953057954728,-28.678982289638586,-25.757714675243097,-29.13065090268802,-26.842833146190493,-29.44301408174904,-25.663880869384133,-25.276792961968027,-25.373991079468222
Episode feedback,0.8,0.31763527022281035,0.279669762353282,0.2293577978645376,0.1364653242321417,0.10020040070120201,0.07014028049084141,0.03807615226645676,0.026052104182312522,0.02204408815426444,0.012024048084144241,0.0100200400701202,0.00400801602804808,0.0050100200350601,0.00200400801402404,0.0,0.00100200400701202,0.00100200400701202,0.00100200400701202,0.0,0.0,0.0
total seconds,0.0,80.80753827095032,165.11716866493225,225.53152990341187,292.83090257644653,373.9457895755768,452.44911217689514,526.1152939796448,599.400901556015,669.5649528503418,737.8019926548004,804.8569452762604,868.2998931407928,933.5360779762268,991.0312247276306,1045.0737755298615,1092.714584350586,1140.4691052436829,1188.4989488124847,1236.05859375,1283.9592859745026,1331.394956111908
total minutes,0.0,1.3467923045158385,2.7519528110822042,3.758858831723531,4.880515042940775,6.232429826259613,7.540818536281586,8.76858823299408,9.990015025933584,11.15941588083903,12.296699877580007,13.414282421271006,14.47166488567988,15.558934632937113,16.517187078793842,17.417896258831025,18.21190973917643,19.007818420728047,19.808315813541412,20.6009765625,21.399321432908376,22.189915935198467
cummulative feedback,0.0,317.0,588.0,763.0,885.0,985.0,1055.0,1093.0,1119.0,1141.0,1153.0,1163.0,1167.0,1172.0,1174.0,1174.0,1175.0,1176.0,1177.0,1177.0,1177.0,1177.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,998.0,969.0,763.0,894.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
