,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,883.0,1229.0,2228.0,3227.0,4226.0,5225.0,6224.0,7223.0,8222.0,9221.0,10220.0,11219.0,12218.0,13217.0,14216.0,15215.0,16214.0,17213.0,18212.0,19211.0,20210.0
Episode reward,0.0,59.14561046564815,85.98493076482288,-40.01432825134713,-34.89100705012114,-36.51330660122505,-32.912084146992605,-32.335624295491684,-31.29891616545625,-30.99647028925687,-33.373157565416456,-33.450154603583904,-33.05124773120488,-33.36478861388909,-31.84071434740423,-32.82663577837908,-32.082731264250114,-32.96876178638841,-32.51235670869478,-31.633316566230693,-31.369049520198633,-32.687057696034174
Episode feedback,0.8,0.46651532296649795,0.4405797088678849,0.26252504983714925,0.17735470924112753,0.14228456899570685,0.08416833658900968,0.06613226446279333,0.024048096168288482,0.02304609216127646,0.014028056098168281,0.012024048084144241,0.00400801602804808,0.007014028049084141,0.0030060120210360602,0.00100200400701202,0.0,0.0,0.0,0.0,0.0,0.0
total seconds,0.0,66.79337406158447,94.64945363998413,163.35839867591858,225.1260907649994,282.1940448284149,335.9190979003906,387.6898374557495,437.93534803390503,488.42903876304626,537.9160890579224,587.7584939002991,637.2586641311646,686.8521914482117,735.8839073181152,784.806667804718,835.2076435089111,889.2056362628937,940.9722728729248,991.9228410720825,1041.7962861061096,1090.9916865825653
total minutes,0.0,1.1132229010264079,1.5774908939997354,2.7226399779319763,3.7521015127499897,4.703234080473582,5.598651631673177,6.461497290929159,7.29892246723175,8.140483979384104,8.965268150965374,9.795974898338319,10.620977735519409,11.447536524136861,12.264731788635254,13.080111130078633,13.920127391815186,14.820093937714894,15.682871214548747,16.532047351201374,17.363271435101826,18.183194776376087
cummulative feedback,0.0,411.0,563.0,825.0,1002.0,1144.0,1228.0,1294.0,1318.0,1341.0,1355.0,1367.0,1371.0,1378.0,1381.0,1382.0,1382.0,1382.0,1382.0,1382.0,1382.0,1382.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,881.0,345.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
