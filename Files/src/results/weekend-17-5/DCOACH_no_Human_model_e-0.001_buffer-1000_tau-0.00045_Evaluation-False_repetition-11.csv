,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,1000.0,1901.0,2900.0,3899.0,4898.0,5897.0,6896.0,7895.0,8894.0,9893.0,10892.0,11891.0,12890.0,13889.0,14888.0,15887.0,16886.0,17885.0,18884.0,19883.0,20882.0
Episode reward,0.0,-38.717019864611004,66.97408383578423,-33.69742989505198,-35.26314024430336,-33.985938031213045,-33.37610121187486,-30.31329639623159,-31.40370778213149,-30.439485338197784,-29.58306965272058,-29.443608656196695,-28.613951939925915,-32.240177647038976,-28.631317461156506,-29.712922584199802,-28.230479080504793,-28.10963643195513,-31.26353352584426,-29.04168962542513,-28.743330847650427,-30.051113709089307
Episode feedback,0.8,0.48396793538680566,0.34666666628148146,0.24749498973196896,0.15430861707985108,0.07615230453291352,0.050100200350601004,0.04709418832956494,0.027054108189324542,0.01803607212621636,0.01102204407713222,0.00901803606310818,0.0050100200350601,0.0,0.0030060120210360602,0.00200400801402404,0.00200400801402404,0.00100200400701202,0.0,0.0,0.0,0.0
total seconds,0.0,72.08591747283936,132.29185152053833,198.5902488231659,256.7862582206726,308.73081278800964,359.1026439666748,409.0398762226105,458.0303509235382,506.58191752433777,554.8003561496735,602.6873784065247,650.8601522445679,698.5830459594727,746.5211138725281,794.247198343277,842.2174642086029,890.0411508083344,937.8257794380188,985.5721614360809,1032.9944005012512,1081.047828912735
total minutes,0.0,1.2014319578806558,2.204864192008972,3.3098374803860984,4.2797709703445435,5.145513546466828,5.9850440661112465,6.817331270376841,7.63383918205897,8.443031958738963,9.246672602494558,10.044789640108744,10.847669204076132,11.64305076599121,12.442018564542135,13.237453305721283,14.036957736810049,14.834019180138906,15.630429657300313,16.42620269060135,17.21657334168752,18.01746381521225
cummulative feedback,0.0,483.0,795.0,1042.0,1196.0,1272.0,1322.0,1369.0,1396.0,1414.0,1425.0,1434.0,1439.0,1439.0,1442.0,1444.0,1446.0,1447.0,1447.0,1447.0,1447.0,1447.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,998.0,900.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
