,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,1000.0,1460.0,2293.0,3292.0,4291.0,5290.0,6289.0,7288.0,8287.0,9286.0,10285.0,11284.0,12283.0,13282.0,14281.0,15280.0,16279.0,17278.0,18277.0,19276.0,20275.0
Episode reward,0.0,-46.26853546438625,78.87262788348664,64.31308441017822,-39.194067398804386,-34.9592032686276,-36.38275673552658,-35.39572845650076,-33.96260527147318,-31.67586940196121,-33.69884536405458,-33.32081350734792,-34.135137286688185,-32.533001907659155,-34.354502925449914,-33.282810304900835,-33.77228211560868,-31.40122851078629,-33.74586406067586,-34.31102463352071,-33.49843046483427,-32.99043329140259
Episode feedback,0.8,0.4448897791133369,0.32244008644348565,0.27163461505813147,0.19939879739539199,0.12625250488351453,0.0851703405960217,0.05310621237163706,0.027054108189324542,0.03106212421737262,0.01703406811920434,0.013026052091156261,0.0030060120210360602,0.0030060120210360602,0.0,0.0030060120210360602,0.00100200400701202,0.00100200400701202,0.0,0.0,0.00100200400701202,0.0
total seconds,0.0,87.68093037605286,129.69469928741455,196.84104371070862,264.3732907772064,322.8249623775482,377.5906934738159,430.2712359428406,481.1593008041382,531.9200754165649,581.7006542682648,631.4381470680237,680.6305043697357,729.7223658561707,778.8510994911194,828.2001297473907,877.5338850021362,926.6616215705872,975.4948942661285,1024.7309875488281,1073.4800906181335,1122.5106029510498
total minutes,0.0,1.461348839600881,2.161578321456909,3.2806840618451436,4.40622151295344,5.380416039625803,6.293178224563599,7.17118726571401,8.01932168006897,8.865334590276083,9.69501090447108,10.523969117800394,11.343841739495595,12.162039430936177,12.980851658185323,13.803335495789845,14.625564750035604,15.444360359509785,16.258248237768807,17.07884979248047,17.89133484363556,18.708510049184163
cummulative feedback,0.0,444.0,592.0,818.0,1017.0,1143.0,1228.0,1281.0,1308.0,1339.0,1356.0,1369.0,1372.0,1375.0,1375.0,1378.0,1379.0,1380.0,1380.0,1380.0,1381.0,1381.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,998.0,459.0,832.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
