,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,1000.0,1999.0,2998.0,3997.0,4996.0,5995.0,6994.0,7993.0,8859.0,9858.0,10857.0,11856.0,12855.0,13854.0,14853.0,15852.0,16851.0,17850.0,18849.0,19848.0,20847.0
Episode reward,0.0,-64.61204216060263,-65.05992968407315,-65.15531218514785,-80.0560524001048,-46.139152176989064,-56.76829467269718,-96.13948079375587,-98.95416373568892,29.216119402621317,-58.5374783569791,-62.2592090400729,-47.98845381018843,-77.8437733166354,-99.49143698701307,-99.56198806930698,-89.97850906865558,-83.24850857611725,-77.60294895018615,-68.64413678524072,-98.98848391264606,-95.40086225771196
Episode feedback,0.8,0.31863727422982235,0.2444889777109329,0.1803607212621636,0.10220440871522604,0.08917835662406978,0.054108216378649085,0.028056112196336563,0.013026052091156261,0.01040462426542818,0.00801603205609616,0.012024048084144241,0.0060120240420721205,0.0060120240420721205,0.0,0.00100200400701202,0.0,0.0,0.0,0.0,0.0,0.0
total seconds,0.0,81.08030843734741,157.5557198524475,229.31516695022583,296.2151370048523,361.9641478061676,420.2894654273987,475.6722536087036,529.1486277580261,575.1767888069153,627.7274651527405,681.1337487697601,734.1903164386749,786.9641597270966,839.0009319782257,891.5515224933624,944.1300182342529,996.3648717403412,1047.9063608646393,1099.850089788437,1151.7336673736572,1204.027777671814
total minutes,0.0,1.35133847395579,2.6259286642074584,3.8219194491704305,4.936918950080871,6.03273579676946,7.004824423789978,7.927870893478394,8.819143795967102,9.586279813448588,10.46212441921234,11.352229146162669,12.236505273977915,13.116069328784942,13.983348866303762,14.85919204155604,15.735500303904216,16.606081195672353,17.465106014410654,18.33083482980728,19.195561122894286,20.067129627863565
cummulative feedback,0.0,318.0,562.0,742.0,844.0,933.0,987.0,1015.0,1028.0,1037.0,1045.0,1057.0,1063.0,1069.0,1069.0,1070.0,1070.0,1070.0,1070.0,1070.0,1070.0,1070.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,865.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
