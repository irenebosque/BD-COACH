,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,1000.0,1999.0,2998.0,3997.0,4996.0,5995.0,6994.0,7993.0,8992.0,9991.0,10990.0,11989.0,12988.0,13987.0,14986.0,15985.0,16984.0,17983.0,18982.0,19981.0,20980.0
Episode reward,0.0,-58.81827434278743,-69.26114172902037,-69.38203043303679,-59.780953758154844,-97.4380602115854,-49.13927586838315,-59.85903205573547,-42.60891386949444,-99.49089086998754,-90.94896517570002,-99.57975055061388,-98.24338884008402,-79.52612185590218,-99.7544917106633,-99.87570857729608,-99.87833032548203,-77.97846676825775,-75.6067720910849,-66.50989912813584,-99.84061097136038,-99.88245464118341
Episode feedback,0.8,0.31863727422982235,0.10921843676431019,0.08116232456797362,0.10721442875028614,0.06112224442773322,0.06613226446279333,0.05110220435761302,0.02104208414725242,0.007014028049084141,0.00200400801402404,0.0030060120210360602,0.00200400801402404,0.00100200400701202,0.0030060120210360602,0.0,0.0,0.00100200400701202,0.00100200400701202,0.0,0.0,0.00100200400701202
total seconds,0.0,79.1765022277832,142.17274618148804,203.36130142211914,266.71201968193054,324.59692549705505,382.82469177246094,439.69096970558167,493.64527344703674,546.2700583934784,598.369772195816,651.0360269546509,703.295881986618,755.7962548732758,808.2725830078125,860.6953964233398,913.7929809093475,967.1278328895569,1019.518753528595,1071.3361518383026,1123.4420249462128,1175.176142692566
total minutes,0.0,1.3196083704630535,2.3695457696914675,3.389355023701986,4.4452003280321755,5.4099487582842505,6.380411529541016,7.328182828426361,8.227421224117279,9.10450097322464,9.972829536596935,10.850600449244181,11.7215980331103,12.59660424788793,13.471209716796874,14.344923273722332,15.229883015155792,16.11879721482595,16.991979225476584,17.855602530638375,18.724033749103548,19.586269044876097
cummulative feedback,0.0,318.0,427.0,508.0,615.0,676.0,742.0,793.0,814.0,821.0,823.0,826.0,828.0,829.0,832.0,832.0,832.0,833.0,834.0,834.0,834.0,835.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
