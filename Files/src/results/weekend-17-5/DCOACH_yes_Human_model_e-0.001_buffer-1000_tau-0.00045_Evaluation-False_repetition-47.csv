,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,1000.0,1999.0,2998.0,3997.0,4996.0,5995.0,6994.0,7993.0,8992.0,9991.0,10959.0,11500.0,12499.0,13209.0,14208.0,14794.0,15535.0,16534.0,17533.0,18165.0,19164.0
Episode reward,0.0,-69.0626630708355,-62.2517796963538,-62.95112518530647,-64.09699327822923,-64.9474244994935,-57.3008182816321,-66.47091619829345,-65.39343429023423,-62.44193957614884,-67.33699733333921,41.13586801529891,66.37504084635334,-65.78586429718152,65.79179346176858,-39.79728430652005,82.82330053035729,72.30003640006532,-41.9302706548013,-57.2304217743119,64.12000930379108,-55.47054762226733
Episode feedback,0.8,0.09118236463809383,0.2555110217880651,0.01102204407713222,0.00801603205609616,0.00901803606310818,0.025050100175300502,0.00801603205609616,0.013026052091156261,0.0050100200350601,0.0050100200350601,0.005170630811612584,0.0018518518484224966,0.0,0.0028208744671073703,0.00200400801402404,0.0034188034129593106,0.004054054048575602,0.00100200400701202,0.0,0.0,0.0
total seconds,0.0,58.12272906303406,129.84696626663208,179.86879801750183,229.09893774986267,278.689106464386,329.81181836128235,379.0058469772339,426.90723514556885,476.08240485191345,524.8366260528564,569.8659112453461,595.6250879764557,642.0356919765472,675.1843528747559,722.2865676879883,750.0043160915375,786.170946598053,834.7575685977936,884.1697506904602,916.3574435710907,966.4351005554199
total minutes,0.0,0.9687121510505676,2.164116104443868,2.997813300291697,3.818315629164378,4.6448184410731,5.4968636393547055,6.3167641162872314,7.115120585759481,7.934706747531891,8.747277100880941,9.497765187422434,9.927084799607595,10.700594866275788,11.253072547912598,12.03810946146647,12.500071934858958,13.102849109967549,13.91262614329656,14.73616251150767,15.272624059518177,16.107251675923667
cummulative feedback,0.0,91.0,346.0,357.0,365.0,374.0,399.0,407.0,420.0,425.0,430.0,435.0,436.0,436.0,438.0,440.0,442.0,445.0,446.0,446.0,446.0,446.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,967.0,540.0,998.0,709.0,998.0,585.0,740.0,998.0,998.0,631.0,998.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
