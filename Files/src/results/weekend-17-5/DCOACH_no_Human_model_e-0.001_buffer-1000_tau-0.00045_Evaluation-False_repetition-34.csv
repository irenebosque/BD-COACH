,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,1000.0,1999.0,2998.0,3997.0,4996.0,5995.0,6994.0,7993.0,8992.0,9991.0,10990.0,11989.0,12988.0,13987.0,14986.0,15985.0,16984.0,17983.0,18982.0,19981.0,20980.0
Episode reward,0.0,-53.064387107457925,-50.48246842984133,-50.62394001974655,-52.53160433168824,-49.532268547715205,-49.35224203010299,-49.63477821351425,-49.18937664698609,-50.74033655577294,-52.65512773999792,-49.90689477178819,-49.716237727411034,-50.06811446404943,-50.35248451067295,-50.52395146250507,-51.438131795504766,-49.74021034067097,-50.9722550754709,-50.659214990236244,-50.58421712471332,-50.29833990791349
Episode feedback,0.8,0.3296593183069546,0.3236472942648825,0.1803607212621636,0.0851703405960217,0.08817635261705777,0.0551102203856611,0.04108216428749282,0.024048096168288482,0.00801603205609616,0.00901803606310818,0.0100200400701202,0.0030060120210360602,0.0050100200350601,0.00100200400701202,0.0,0.0,0.0,0.0,0.0,0.0,0.0
total seconds,0.0,67.43675017356873,139.96668791770935,202.3528437614441,256.86887383461,311.2570459842682,363.81481170654297,414.758013010025,464.70551800727844,513.7038283348083,562.838339805603,612.3073341846466,661.5720567703247,710.7571592330933,760.0926940441132,808.7326328754425,857.4685835838318,906.5745320320129,956.2977073192596,1005.3961672782898,1055.9477217197418,1104.8147420883179
total minutes,0.0,1.1239458362261454,2.3327781319618226,3.372547396024068,4.2811478972435,5.187617433071137,6.06358019510905,6.912633550167084,7.745091966787974,8.561730472246806,9.38063899676005,10.205122236410777,11.026200946172079,11.845952653884888,12.668211567401887,13.478877214590709,14.29114305973053,15.109575533866883,15.938295121987661,16.756602787971495,17.599128695329032,18.4135790348053
cummulative feedback,0.0,329.0,652.0,832.0,917.0,1005.0,1060.0,1101.0,1125.0,1133.0,1142.0,1152.0,1155.0,1160.0,1161.0,1161.0,1161.0,1161.0,1161.0,1161.0,1161.0,1161.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
