,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30
Accumulated time steps,0.0,694.0,1077.0,1238.0,1397.0,2284.0,3283.0,4266.0,5265.0,5439.0,6273.0,7272.0,8161.0,9160.0,9413.0,9874.0,9965.0,10964.0,11095.0,12052.0,12584.0,13583.0,14582.0,14738.0,15737.0,16568.0,17567.0,18390.0,18740.0,19739.0,20525.0
Episode reward,0.0,56.63139151981889,78.62127349072975,89.9639123496444,89.65172753509445,47.54750690237922,-68.74199338804789,19.10780832962169,-87.66544229005234,89.31221097474597,24.150907979494093,-84.83372018259406,20.55374529980213,-90.88988828566805,80.17019449741443,57.84519590382674,94.92255294998843,-90.71610386088234,90.77539970930387,12.322197685053567,53.62421341895153,-86.93668098781771,-81.53348592518094,89.18190794727609,-99.54353622925024,21.340664343931806,-95.71043383398204,22.16314659088141,75.8659214347847,-88.8823038393009,25.545072113837605
Episode feedback,0.8,0.29479768743526347,0.14397905721471452,0.237499998515625,0.2025316442877744,0.1738148982236852,0.1052104207362621,0.1048879835999104,0.06613226446279333,0.057803467873968395,0.04201680667224873,0.037074148259444745,0.02027027024744339,0.01102204407713222,0.007936507905013858,0.010869565193761815,0.011111110987654323,0.0050100200350601,0.0,0.001046025103508342,0.0037664783356563497,0.00400801602804808,0.00100200400701202,0.0,0.00100200400701202,0.0012048192756568443,0.0,0.0,0.0,0.0,0.0
total seconds,0.0,57.94583988189697,86.88893842697144,100.5462794303894,113.74374651908875,178.103285074234,242.64316749572754,306.1218855381012,366.3261024951935,377.4220700263977,426.76202964782715,484.77731227874756,537.9797875881195,594.5219342708588,609.2218618392944,636.0800895690918,642.0302555561066,696.6686680316925,704.5104308128357,756.3760678768158,785.5542078018188,839.2876291275024,892.2043342590332,901.4694716930389,954.7553863525391,999.5481038093567,1053.0997443199158,1097.457552433014,1116.7018055915833,1170.170788526535,1212.8748879432678
total minutes,0.0,0.9657639980316162,1.4481489737828572,1.6757713238398233,1.8957291086514791,2.968388084570567,4.044052791595459,5.10203142563502,6.105435041586558,6.290367833773295,7.112700494130452,8.07962187131246,8.966329793135325,9.908698904514313,10.153697697321574,10.60133482615153,10.700504259268444,11.611144467194874,11.741840513547261,12.60626779794693,13.092570130030314,13.98812715212504,14.870072237650554,15.024491194883982,15.912589772542317,16.659135063489277,17.55166240533193,18.290959207216897,18.611696759859722,19.50284647544225,20.214581465721132
cummulative feedback,0.0,204.0,259.0,297.0,329.0,483.0,588.0,691.0,757.0,767.0,802.0,839.0,857.0,868.0,870.0,875.0,876.0,881.0,881.0,882.0,884.0,888.0,889.0,889.0,890.0,891.0,891.0,891.0,891.0,891.0,891.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,692.0,382.0,160.0,158.0,886.0,998.0,982.0,998.0,173.0,833.0,998.0,888.0,998.0,252.0,460.0,90.0,998.0,130.0,956.0,531.0,998.0,998.0,155.0,998.0,830.0,998.0,822.0,349.0,998.0,785.0
e,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
