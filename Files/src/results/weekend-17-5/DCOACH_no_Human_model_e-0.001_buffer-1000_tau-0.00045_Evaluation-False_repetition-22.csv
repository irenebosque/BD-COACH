,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,622.0,1621.0,2620.0,3619.0,4618.0,5617.0,6616.0,7615.0,8614.0,9613.0,10612.0,11611.0,12610.0,13609.0,14608.0,15607.0,16606.0,17605.0,18604.0,19603.0,20602.0
Episode reward,0.0,75.79788729149158,-32.444675151983844,-34.489373597241226,-33.500306403852385,-31.58121072278186,-31.76638934278562,-31.36304920282657,-31.01512507407535,-32.85546961088998,-31.178323221831572,-33.28509808854882,-32.07020498071408,-32.91978957535522,-32.003860647290274,-32.01692472954054,-31.498696651054768,-30.757200433576585,-32.8399841479982,-31.27695885745579,-32.78927360008696,-31.2025325298301
Episode feedback,0.8,0.4709677411758585,0.3226452902578705,0.249498997745993,0.15330661307283908,0.0901803606310818,0.0751503005259015,0.05310621237163706,0.024048096168288482,0.013026052091156261,0.01703406811920434,0.00801603205609616,0.007014028049084141,0.00400801602804808,0.00200400801402404,0.00400801602804808,0.0,0.0,0.0,0.00100200400701202,0.0,0.0
total seconds,0.0,45.82637071609497,118.56580543518066,184.79916167259216,243.9219901561737,297.9186797142029,350.5602731704712,402.13011479377747,452.3029839992523,503.3475430011749,557.6957659721375,609.870728969574,662.0968232154846,713.9952166080475,764.7288420200348,814.2227187156677,862.9969322681427,912.8515636920929,961.9012820720673,1010.9799420833588,1059.578901052475,1108.1938047409058
total minutes,0.0,0.7637728452682495,1.976096757253011,3.079986027876536,4.065366502602895,4.965311328570048,5.842671219507853,6.702168579896291,7.538383066654205,8.389125716686248,9.294929432868958,10.1645121494929,11.034947053591411,11.899920276800792,12.745480700333912,13.570378645261128,14.383282204469046,15.214192728201548,16.031688034534454,16.849665701389313,17.659648350874583,18.469896745681762
cummulative feedback,0.0,292.0,614.0,863.0,1016.0,1106.0,1181.0,1234.0,1258.0,1271.0,1288.0,1296.0,1303.0,1307.0,1309.0,1313.0,1313.0,1313.0,1313.0,1314.0,1314.0,1314.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,620.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
