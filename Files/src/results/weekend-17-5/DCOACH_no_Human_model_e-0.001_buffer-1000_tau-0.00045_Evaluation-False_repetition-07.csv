,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,990.0,1989.0,2988.0,3987.0,4986.0,5985.0,6984.0,7943.0,8942.0,9941.0,10940.0,11939.0,12938.0,13937.0,14936.0,15935.0,16934.0,17933.0,18932.0,19931.0,20930.0
Episode reward,0.0,57.39070837367155,-39.95782711677097,-37.285537866956325,-36.293526619730244,-33.764376284870075,-34.07817324511124,-36.30101391987236,67.53855572838444,-34.335960632856185,-33.7183758375362,-34.54662361871825,-34.86212604929449,-33.97229322455864,-32.16536322296954,-32.51094939420136,-33.803515617878006,-34.47127434762246,-34.40256919555987,-33.34022307726606,-34.48123004963444,-32.3714365045326
Episode feedback,0.8,0.4848178132744759,0.28156312597037764,0.1793587172551516,0.1603206411219232,0.10621242474327412,0.05110220435761302,0.028056112196336563,0.037578288060983,0.01603206411219232,0.01603206411219232,0.007014028049084141,0.0060120240420721205,0.00400801602804808,0.00100200400701202,0.0,0.0,0.00200400801402404,0.0,0.0,0.0,0.0
total seconds,0.0,77.43212223052979,140.27349710464478,197.31971168518066,253.34236025810242,305.83958315849304,356.2533872127533,405.3537211418152,452.92522740364075,501.3805944919586,549.6012263298035,598.1222860813141,646.2265999317169,693.9168128967285,742.1691069602966,789.59996342659,837.2717659473419,885.1661682128906,934.9115946292877,983.5221171379089,1032.1086869239807,1081.2809898853302
total minutes,0.0,1.2905353705088298,2.337891618410746,3.2886618614196776,4.222372670968373,5.097326385974884,5.937556453545889,6.755895352363586,7.548753790060679,8.356343241532644,9.160020438830058,9.968704768021901,10.770443332195281,11.565280214945476,12.369485116004943,13.159999390443167,13.954529432455699,14.752769470214844,15.581859910488129,16.392035285631817,17.20181144873301,18.02134983142217
cummulative feedback,0.0,479.0,760.0,939.0,1099.0,1205.0,1256.0,1284.0,1320.0,1336.0,1352.0,1359.0,1365.0,1369.0,1370.0,1370.0,1370.0,1372.0,1372.0,1372.0,1372.0,1372.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,988.0,998.0,998.0,998.0,998.0,998.0,998.0,958.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
