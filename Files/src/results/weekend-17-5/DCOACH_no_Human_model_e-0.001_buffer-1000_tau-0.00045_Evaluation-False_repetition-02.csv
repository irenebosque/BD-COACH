,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,621.0,1620.0,2619.0,3618.0,4617.0,5616.0,6615.0,7614.0,8613.0,9612.0,10611.0,11610.0,12609.0,13608.0,14607.0,15606.0,16605.0,17604.0,18603.0,19602.0,20601.0
Episode reward,0.0,75.06446452035769,-38.72563533980167,-33.3804929919652,-32.72843948281143,-32.617002417612575,-33.10537734336587,-32.77847643766903,-33.77948488485311,-33.96682476497693,-34.27304802122999,-32.61646532289728,-32.32040114428277,-34.37706425413863,-33.4300595825961,-33.552800738095726,-33.635303454260175,-32.939480118828754,-33.16589553722794,-33.29793701524198,-34.073187763359336,-33.324479032019376
Episode feedback,0.8,0.48788368257207804,0.34368737440512287,0.24248496969690886,0.16833667317801937,0.11623246481339432,0.0651302604557813,0.037074148259444745,0.01603206411219232,0.0200400801402404,0.01703406811920434,0.00801603205609616,0.00400801602804808,0.00801603205609616,0.00100200400701202,0.0,0.0,0.0,0.0,0.0,0.0,0.00100200400701202
total seconds,0.0,42.1771240234375,107.10155177116394,169.79755473136902,228.78196692466736,282.93242383003235,334.6552402973175,387.2389168739319,435.95831322669983,485.00743317604065,533.35937666893,581.3368067741394,629.1496903896332,677.3984115123749,725.0797448158264,773.0941224098206,821.0913081169128,868.6968922615051,916.2593810558319,963.8547360897064,1011.9934620857239,1059.7592067718506
total minutes,0.0,0.7029520670572916,1.7850258628527322,2.829959245522817,3.8130327820777894,4.715540397167206,5.577587338288625,6.453981947898865,7.265971887111664,8.083457219600678,8.889322944482167,9.68894677956899,10.485828173160552,11.289973525206248,12.084662413597107,12.884902040163675,13.68485513528188,14.478281537691752,15.270989684263865,16.064245601495106,16.866557701428732,17.66265344619751
cummulative feedback,0.0,302.0,645.0,887.0,1055.0,1171.0,1236.0,1273.0,1289.0,1309.0,1326.0,1334.0,1338.0,1346.0,1347.0,1347.0,1347.0,1347.0,1347.0,1347.0,1347.0,1348.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,619.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
