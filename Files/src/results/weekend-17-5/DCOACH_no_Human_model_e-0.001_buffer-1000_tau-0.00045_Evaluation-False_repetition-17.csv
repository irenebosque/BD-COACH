,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,1000.0,1999.0,2576.0,3575.0,4574.0,5573.0,6572.0,7571.0,8570.0,9569.0,10568.0,11567.0,12566.0,13565.0,14564.0,15563.0,16562.0,17561.0,18560.0,19559.0,20558.0
Episode reward,0.0,-63.205447100363074,-54.50618796337828,71.20449107695529,-45.360535014545356,-46.2032977794392,-44.81199515590423,-46.705548277201444,-44.626878466845895,-45.01781063792686,-45.40165984383095,-42.61236146405057,-44.58097622453462,-44.04331375886617,-44.12777373608687,-44.82266731504854,-43.9032866763655,-44.92581378916876,-41.13699234348231,-42.3552797919177,-44.624317258371136,-43.23091193643139
Episode feedback,0.8,0.007014028049084141,0.3316633263209786,0.21527777740403164,0.17835671324813956,0.09819639268717796,0.08817635261705777,0.04709418832956494,0.033066132231396664,0.02104208414725242,0.01102204407713222,0.0100200400701202,0.00400801602804808,0.0050100200350601,0.00200400801402404,0.0,0.0,0.00200400801402404,0.0,0.0,0.0,0.0
total seconds,0.0,44.43754959106445,108.18455386161804,141.99192333221436,197.81483101844788,249.99327397346497,301.9523718357086,351.8925316333771,401.45630264282227,450.42869663238525,499.0210916996002,547.1058385372162,595.0858948230743,642.8765652179718,690.9738004207611,739.6612937450409,787.1199543476105,834.9142572879791,884.6845076084137,936.6472597122192,986.0777475833893,1034.6164863109589
total minutes,0.0,0.7406258265177409,1.803075897693634,2.366532055536906,3.2969138503074644,4.166554566224416,5.032539530595144,5.864875527222951,6.6909383773803714,7.5071449438730875,8.317018194993336,9.118430642286937,9.918098247051239,10.71460942029953,11.516230007012686,12.327688229084014,13.118665905793508,13.91523762146632,14.744741793473562,15.61078766187032,16.434629126389822,17.24360810518265
cummulative feedback,0.0,7.0,338.0,462.0,640.0,738.0,826.0,873.0,906.0,927.0,938.0,948.0,952.0,957.0,959.0,959.0,959.0,961.0,961.0,961.0,961.0,961.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,998.0,998.0,576.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
