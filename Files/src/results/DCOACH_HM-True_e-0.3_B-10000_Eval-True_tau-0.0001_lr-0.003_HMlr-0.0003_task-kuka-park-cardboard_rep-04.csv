,0,1,2,3,4,5,6,7,8,9,10,11,12
Accumulated time steps,0.0,181.0,333.0,597.0,738.0,965.0,1111.0,1190.0,1392.0,1486.0,1541.0,1814.0,1940.0
Episode reward,0.0,65.78901646316176,69.29642764450072,78.62206086521223,67.46352590937452,103.24565510746406,71.3658779287831,52.44868211918885,95.61733994872829,49.411785388221716,33.51143397496619,107.70824698026178,12.494771559952346
Episode feedback,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
total seconds,0.0,28.681775093078613,55.36934852600098,93.6048378944397,119.14389371871948,153.55720376968384,179.61634135246277,198.77261686325073,230.6035132408142,251.313889503479,267.99936747550964,307.1481535434723,331.15846824645996
total minutes,0.0,0.47802958488464353,0.9228224754333496,1.560080631573995,1.985731561978658,2.5592867294947306,2.9936056892077128,3.3128769477208455,3.8433918873469035,4.188564825057983,4.466656124591827,5.1191358923912045,5.519307804107666
cummulative feedback,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
e,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3
buffer size,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0
human model,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
tau,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001
total_success,0.0,1.0,2.0,3.0,4.0,5.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0
total_success_div_episode,0.0,1.0,1.0,1.0,1.0,1.0,1.0,0.8571428571428571,0.75,0.6666666666666666,0.6,0.5454545454545454,0.5
total_policy_loss_agent,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
total_policy_loss_hm,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
success_this_episode,0.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0
timesteps_this_episode,0.0,179.0,151.0,263.0,140.0,226.0,145.0,78.0,201.0,93.0,54.0,272.0,125.0
