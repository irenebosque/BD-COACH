,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,644.0,1183.0,1442.0,1880.0,2144.0,2400.0,2664.0,3197.0,4196.0,5097.0,5338.0,6020.0,6622.0,7259.0,7556.0,7772.0,8560.0,9559.0,10327.0,10788.0,11558.0
Episode reward,0.0,70.28014934550131,73.8006450116686,87.13887259434753,78.75986702060791,88.61338355149238,88.29006484614628,87.55505356783054,74.29766499101066,-50.137345098993755,60.71100147856722,90.6743945353192,77.44437243003507,79.87243672157487,81.31515364294319,91.09780706892593,92.60844328459133,78.33731299532987,-28.705148061895066,82.81788904526562,89.30702847697009,84.17646878052224
Episode feedback,0.8,0.3940809962709019,0.3587360588127583,0.20155038681569618,0.196796338222434,0.21292775584438114,0.1764705875432526,0.19011406771819747,0.16729323276824581,0.0901803606310818,0.06555555548271605,0.08749999963541667,0.04405286337143485,0.03826955068507562,0.029874213789505954,0.030405405302684443,0.032558139383450514,0.016518424375453082,0.007014028049084141,0.003911342889294208,0.004347826077504726,0.001300390115344096
total seconds,0.0,40.244834899902344,74.63574266433716,89.92205262184143,114.86026811599731,130.63310265541077,145.5458264350891,160.9783980846405,190.75114011764526,242.30784678459167,287.7544631958008,300.7962749004364,334.965185880661,365.1043577194214,396.5312604904175,411.67725014686584,423.0423684120178,461.26709723472595,513.4024078845978,550.247104883194,572.8716497421265,610.0953667163849
total minutes,0.0,0.6707472483317057,1.2439290444056192,1.4987008770306904,1.9143378019332886,2.1772183775901794,2.4257637739181517,2.682973301410675,3.179185668627421,4.038464113076528,4.795907719930013,5.013271248340606,5.5827530980110165,6.085072628657023,6.608854341506958,6.861287502447764,7.050706140200297,7.687784953912099,8.556706798076629,9.170785081386565,9.547860829035441,10.168256111939748
cummulative feedback,0.0,253.0,446.0,498.0,584.0,640.0,685.0,735.0,824.0,914.0,973.0,994.0,1024.0,1047.0,1066.0,1075.0,1082.0,1095.0,1102.0,1105.0,1107.0,1108.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,642.0,538.0,258.0,437.0,263.0,255.0,263.0,532.0,998.0,900.0,240.0,681.0,601.0,636.0,296.0,215.0,787.0,998.0,767.0,460.0,769.0
e,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
buffer size,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
