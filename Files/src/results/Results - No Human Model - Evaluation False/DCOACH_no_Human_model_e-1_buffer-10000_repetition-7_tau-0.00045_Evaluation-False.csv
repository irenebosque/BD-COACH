,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,361.0,823.0,1270.0,1632.0,2331.0,2693.0,3692.0,4341.0,4673.0,5022.0,5772.0,6199.0,6779.0,7024.0,8023.0,8538.0,8937.0,9589.0,10588.0,11136.0,11694.0
Episode reward,0.0,83.82645225146133,79.15469389478106,78.43794007508109,82.43116012204246,65.56095765133327,82.53938640902462,-40.32148702051231,73.78247771204568,87.65051743167463,84.89990883157881,67.48792372644354,84.6412067561171,78.19775935916776,90.88513330365342,-33.39226459759054,76.80627265626762,81.44428539844255,76.22863384798436,-36.88655190750247,85.20995353960656,83.19712649768772
Episode feedback,0.8,0.43454038876172596,0.4013015175676757,0.20179372152064187,0.2686980601975123,0.1561604582289965,0.14404432093062516,0.1202404808414424,0.07870370358224738,0.0876132927866668,0.06896551704320254,0.054739652797410346,0.05868544587163041,0.037996545702942065,0.02459016383364687,0.02204408815426444,0.021400778168480978,0.01758793965430166,0.009216589847593564,0.01102204407713222,0.0018281535615573062,0.0071813285328881
total seconds,0.0,22.705217838287354,52.94248366355896,78.5530731678009,100.63932180404663,138.86113667488098,158.88132286071777,211.4839997291565,244.94623064994812,262.63330841064453,281.01776814460754,318.91268038749695,340.9243094921112,369.96678614616394,382.71308159828186,431.6293182373047,457.2719774246216,477.33694219589233,509.30958223342896,557.7460470199585,584.5935583114624,612.0498905181885
total minutes,0.0,0.3784202973047892,0.8823747277259827,1.309217886130015,1.6773220300674438,2.3143522779146832,2.6480220476786296,3.524733328819275,4.082437177499135,4.377221806844076,4.683629469076792,5.315211339791616,5.68207182486852,6.166113102436066,6.378551359971365,7.1938219706217446,7.621199623743693,7.955615703264872,8.488493037223815,9.295767450332642,9.743225971857706,10.200831508636474
cummulative feedback,0.0,156.0,341.0,431.0,528.0,637.0,689.0,809.0,860.0,889.0,913.0,954.0,979.0,1001.0,1007.0,1029.0,1040.0,1047.0,1053.0,1064.0,1065.0,1069.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,359.0,461.0,446.0,361.0,698.0,361.0,998.0,648.0,331.0,348.0,749.0,426.0,579.0,244.0,998.0,514.0,398.0,651.0,998.0,547.0,557.0
e,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
buffer size,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
