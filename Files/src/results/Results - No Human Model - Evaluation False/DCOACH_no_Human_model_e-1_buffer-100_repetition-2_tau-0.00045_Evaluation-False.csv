,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,546.0,1067.0,1425.0,1969.0,2316.0,2946.0,3309.0,3740.0,4240.0,4759.0,5263.0,5674.0,6354.0,7353.0,7999.0,8224.0,9043.0,10042.0,10986.0,11484.0,11810.0
Episode reward,0.0,74.57981110793295,72.6755505463811,83.24392037407081,73.15585471354213,82.21725988596714,70.79045381198775,83.95498312617038,85.83565755973942,81.65715732382154,74.42453519260712,80.64820889100329,81.83385271396554,75.59155274551075,-34.46816020057765,80.26914889414758,94.4991741786386,70.29104517510046,-43.32651424683266,55.45600112552574,74.07262480653866,85.56896735076361
Episode feedback,0.8,0.36948529343844616,0.28076923022928996,0.2997198871156306,0.19705340663526077,0.1560693637107822,0.13354530980358456,0.14364640844296572,0.1348837206165495,0.09819639258878478,0.07722007707100371,0.05367793229885103,0.060975609607376566,0.0486008835808529,0.03607214425243272,0.021705426322937323,0.008928571388711734,0.019559902176577135,0.00901803606310818,0.01166489924531824,0.0,0.0
total seconds,0.0,32.49595069885254,63.3730947971344,85.18300938606262,115.71688604354858,135.1360261440277,168.95194792747498,188.96307706832886,212.49494576454163,238.91185545921326,266.21456956863403,292.08798027038574,313.2763440608978,347.73860454559326,397.38592314720154,429.3090326786041,440.9033753871918,479.9719572067261,526.2849872112274,571.2885177135468,595.0119359493256,610.9198820590973
total minutes,0.0,0.541599178314209,1.0562182466189067,1.4197168231010437,1.9286147673924765,2.2522671024004617,2.8158657987912497,3.149384617805481,3.541582429409027,3.9818642576535543,4.4369094928105675,4.868133004506429,5.221272401014963,5.795643409093221,6.6230987191200255,7.155150544643402,7.34838958978653,7.9995326201121015,8.771416453520457,9.521475295225779,9.916865599155425,10.181998034318289
cummulative feedback,0.0,201.0,347.0,454.0,561.0,615.0,699.0,751.0,809.0,858.0,898.0,925.0,950.0,983.0,1019.0,1033.0,1035.0,1051.0,1060.0,1071.0,1071.0,1071.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,544.0,520.0,357.0,543.0,346.0,629.0,362.0,430.0,499.0,518.0,503.0,410.0,679.0,998.0,645.0,224.0,818.0,998.0,943.0,497.0,325.0
e,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
buffer size,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
