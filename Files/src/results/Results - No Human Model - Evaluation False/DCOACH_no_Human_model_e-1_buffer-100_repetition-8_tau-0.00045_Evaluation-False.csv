,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,562.0,847.0,1618.0,2070.0,2732.0,2991.0,3430.0,3865.0,4047.0,4804.0,5238.0,6184.0,6811.0,7191.0,7821.0,8419.0,9086.0,10085.0,10656.0,11233.0,11727.0
Episode reward,0.0,75.2032607919252,85.50684103191796,57.10013204609471,79.01284067155706,67.29434101488731,87.25863965170115,80.4244049194858,79.3124785781105,90.32725823963594,65.78190413979674,81.33103086657098,59.085602385519394,82.03732601437666,89.93099163102495,85.35526291220262,83.95194064998344,84.9575891126266,-32.525005742383264,84.5227493917262,79.77547767925603,82.30332791827098
Episode feedback,0.8,0.44285714206632654,0.2711267596087086,0.14935064915668747,0.20620842526339594,0.15128593017959768,0.13953488318009735,0.13013698600425347,0.0944700458652764,0.08839778956686305,0.0767195766180958,0.08314087740614116,0.05608465602530724,0.05750798712858149,0.03166226904574599,0.02861685210076812,0.01675041873241136,0.02252252248870492,0.013026052091156261,0.008771929809172054,0.003472222216194059,0.006085192685425573
total seconds,0.0,35.10391855239868,52.28297567367554,93.78187918663025,119.46515965461731,155.4799792766571,170.00523447990417,193.69208240509033,216.6927785873413,226.8521957397461,265.5527296066284,288.30695128440857,335.7690386772156,367.73935437202454,387.1135790348053,418.43758153915405,447.9706938266754,480.9301884174347,529.416969537735,557.4068293571472,585.6014757156372,609.9306616783142
total minutes,0.0,0.5850653092066447,0.8713829278945923,1.5630313197771708,1.9910859942436219,2.591332987944285,2.8334205746650696,3.2282013734181723,3.6115463097890217,3.7808699289957683,4.42587882677714,4.8051158547401425,5.59615064462026,6.128989239533742,6.451892983913422,6.973959692319235,7.46617823044459,8.015503140290578,8.823616158962249,9.290113822619121,9.76002459526062,10.165511027971904
cummulative feedback,0.0,248.0,325.0,440.0,533.0,633.0,669.0,726.0,767.0,783.0,841.0,877.0,930.0,966.0,978.0,996.0,1006.0,1021.0,1034.0,1039.0,1041.0,1044.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,560.0,284.0,770.0,451.0,661.0,258.0,438.0,434.0,181.0,756.0,433.0,945.0,626.0,379.0,629.0,597.0,666.0,998.0,570.0,576.0,493.0
e,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
buffer size,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
