,0,1,2,3,4,5,6,7,8,9,10,11
Accumulated time steps,0.0,849.0,1693.0,2549.0,3398.0,4255.0,5120.0,5970.0,6767.0,7634.0,8529.0,9378.0
Episode reward,0.0,117.18858158899407,98.1681382796842,87.0752215385315,92.34001836574808,96.73730353056952,112.01967935119617,104.82717351121399,82.16547042351586,126.19664249710563,186.49586279280004,153.93428918862432
Episode feedback,0.8,0.12042502937376029,0.12218268075660417,0.10877192969734277,0.1285377356974791,0.07593457935054372,0.025462962933491942,0.04240282680517924,0.11180904508566702,0.04965357961933767,0.055928411570549875,0.09551886781188813
total seconds,0.0,96.12708520889282,193.41239428520203,291.5531759262085,389.5088288784027,487.1017036437988,584.3176732063293,680.3549790382385,772.4294092655182,870.4059085845947,971.490781545639,1068.6703824996948
total minutes,0.0,1.6021180868148803,3.223539904753367,4.859219598770141,6.491813814640045,8.118361727396648,9.738627886772155,11.339249650637308,12.873823487758637,14.50676514307658,16.19151302576065,17.81117304166158
cummulative feedback,0.0,102.0,205.0,298.0,407.0,472.0,494.0,530.0,619.0,662.0,712.0,793.0
e,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5
buffer size,1500.0,1500.0,1500.0,1500.0,1500.0,1500.0,1500.0,1500.0,1500.0,1500.0,1500.0,1500.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
tau,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001
total_success,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
total_success_div_episode,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
total_policy_loss_agent,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
total_policy_loss_hm,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
