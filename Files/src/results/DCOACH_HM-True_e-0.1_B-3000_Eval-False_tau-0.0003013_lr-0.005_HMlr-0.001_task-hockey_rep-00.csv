,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19
Accumulated time steps,0.0,66.0,128.0,183.0,304.0,436.0,559.0,723.0,818.0,928.0,1017.0,1122.0,1253.0,1376.0,1471.0,1602.0,1707.0,1799.0,1865.0,1978.0
Episode reward,0.0,137.02961028880242,132.12641760838085,127.0964005503701,202.33936656947563,226.13476724639136,204.25139603177513,506.5402223112194,187.28438416366916,288.26013674665217,177.20871743120014,191.0718981132665,215.4240503841698,212.88703170464186,167.40126965432088,236.2212690939636,208.06123815941294,167.74930697210246,139.5772739434856,341.31898494999376
Episode feedback,0.8,0.703124989013672,0.8524590024187049,0.4074073998628259,0.7416666604861112,0.6564885446069577,0.6393442570545553,0.6257668673265836,0.5957446745133546,0.614678893443313,0.6136363566632232,0.7019230701738166,0.5307692266863906,0.4672131109244827,0.47872339916251705,0.5076923037869823,0.46153845710059177,0.45054944559835775,0.523076915029586,0.4107142820471939
total seconds,0.0,3.7838196754455566,8.827967405319214,12.395986080169678,22.81487798690796,33.79103231430054,44.114136934280396,57.40145802497864,65.28991603851318,74.35064816474915,81.88966703414917,91.2293131351471,101.08850002288818,109.66803860664368,116.799067735672,126.37389707565308,134.0050344467163,140.80134201049805,146.34147024154663,154.19977807998657
total minutes,0.0,0.06306366125742595,0.14713279008865357,0.20659976800282795,0.380247966448466,0.563183871905009,0.7352356155713399,0.9566909670829773,1.0881652673085531,1.2391774694124857,1.3648277839024863,1.5204885522524516,1.684808333714803,1.8278006434440612,1.9466511289278665,2.106231617927551,2.2334172407786053,2.3466890335083006,2.439024504025777,2.5699963013331097
cummulative feedback,0.0,45.0,97.0,119.0,208.0,294.0,372.0,474.0,530.0,597.0,651.0,724.0,793.0,850.0,895.0,961.0,1009.0,1050.0,1084.0,1130.0
e,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1
buffer size,3000.0,3000.0,3000.0,3000.0,3000.0,3000.0,3000.0,3000.0,3000.0,3000.0,3000.0,3000.0,3000.0,3000.0,3000.0,3000.0,3000.0,3000.0,3000.0,3000.0
human model,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
tau,0.0003013,0.0003013,0.0003013,0.0003013,0.0003013,0.0003013,0.0003013,0.0003013,0.0003013,0.0003013,0.0003013,0.0003013,0.0003013,0.0003013,0.0003013,0.0003013,0.0003013,0.0003013,0.0003013,0.0003013
total_success,0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0
total_success_div_episode,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
total_policy_loss_agent,0.0,0.0,0.0,0.0,0.004791667684912682,0.00423993868753314,0.0043750000186264515,0.003541667712852359,0.004375660326331854,0.003958333749324083,0.005000001285225153,0.005000000353902578,0.0043750000186264515,0.005000000819563866,0.004083105828613043,0.004166666883975267,0.0031250007450580597,0.003958333749324083,0.00458333408460021,0.004166667815297842
total_policy_loss_hm,0.0,0.0,0.0,0.16507576406002045,0.15613014996051788,0.27505606412887573,0.3065814673900604,0.3393681049346924,0.1722838133573532,0.32977914810180664,0.2599368095397949,0.20418357849121094,0.28161799907684326,0.28009486198425293,0.1466517597436905,0.246784508228302,0.2532539963722229,0.2004159688949585,0.39445552229881287,0.16631585359573364
