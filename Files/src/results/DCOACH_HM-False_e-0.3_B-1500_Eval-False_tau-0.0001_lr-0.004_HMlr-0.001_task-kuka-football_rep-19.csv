,0,1,2,3,4,5,6,7
Accumulated time steps,0.0,2002.0,4003.0,6004.0,8005.0,10006.0,12007.0,14008.0
Episode reward,0.0,1515.8717467188835,1230.8353538960218,1420.2061904072762,1278.1655012369156,1292.9846132099628,1194.1979329884052,1023.846509128809
Episode feedback,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0
total seconds,0.0,214.93352675437927,430.85434556007385,646.7520034313202,862.6705875396729,1078.6597683429718,1294.6529078483582,1510.5846781730652
total minutes,0.0,3.5822254459063214,7.180905759334564,10.77920005718867,14.377843125661213,17.977662805716196,21.5775484641393,25.17641130288442
cummulative feedback,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
e,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3
buffer size,1500.0,1500.0,1500.0,1500.0,1500.0,1500.0,1500.0,1500.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
tau,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001
total_success,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
total_success_div_episode,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
total_policy_loss_agent,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
total_policy_loss_hm,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
