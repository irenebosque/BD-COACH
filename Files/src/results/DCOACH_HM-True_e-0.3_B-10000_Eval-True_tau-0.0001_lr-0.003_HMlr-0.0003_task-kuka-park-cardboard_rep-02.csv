,0,1,2,3,4,5,6,7,8,9,10,11,12,13
Accumulated time steps,0.0,151.0,287.0,420.0,684.0,975.0,1363.0,1433.0,1934.0,2170.0,2248.0,2555.0,2682.0,3183.0
Episode reward,0.0,73.0016874183683,67.93550361800474,62.484196688677414,67.8901608865933,97.63378922746989,116.56479576556887,45.743292009774954,245.87617296564642,114.39420299641709,49.340628806824725,104.98240949737811,35.498300469089486,8.503412863734665
Episode feedback,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
total seconds,0.0,25.55473494529724,50.58804130554199,75.30113744735718,113.52558779716492,154.52547764778137,205.52224588394165,223.74536752700806,286.428991317749,321.75417947769165,340.82134890556335,383.48370146751404,407.59814620018005,470.27505898475647
total minutes,0.0,0.42591224908828734,0.8431340217590332,1.255018957455953,1.8920931299527486,2.575424627463023,3.425370764732361,3.7290894587834678,4.773816521962484,5.362569657961528,5.680355815092723,6.391395024458567,6.793302436669667,7.8379176497459415
cummulative feedback,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
e,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3
buffer size,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0
human model,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
tau,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001
total_success,0.0,1.0,2.0,3.0,4.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0
total_success_div_episode,0.0,1.0,1.0,1.0,1.0,1.0,0.8333333333333334,0.7142857142857143,0.625,0.5555555555555556,0.5,0.45454545454545453,0.4166666666666667,0.38461538461538464
total_policy_loss_agent,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
total_policy_loss_hm,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
success_this_episode,0.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
timesteps_this_episode,0.0,149.0,135.0,132.0,263.0,290.0,387.0,69.0,500.0,235.0,77.0,306.0,126.0,500.0
