,0,1,2,3,4,5,6,7,8,9,10,11,12
Accumulated time steps,0.0,132.0,278.0,475.0,640.0,847.0,1050.0,1118.0,1302.0,1375.0,1459.0,1545.0,1571.0
Episode reward,0.0,64.8222715965012,71.734863343824,65.6482310325446,78.97281429102006,80.05591283943218,91.4498283025914,38.310106413578865,50.3602428322478,39.5808690530901,35.64857698202671,42.30572299531518,13.571937141279141
Episode feedback,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
total seconds,0.0,23.59605383872986,49.66824460029602,80.99714970588684,109.02100038528442,141.3613476753235,173.3051998615265,191.3228199481964,221.30857396125793,239.83938074111938,259.49994587898254,279.3830306529999,293.0789523124695
total minutes,0.0,0.39326756397883095,0.8278040766716004,1.349952495098114,1.8170166730880737,2.3560224612553915,2.8884199976921083,3.1887136658032733,3.6884762326876324,3.99732301235199,4.324999097983042,4.6563838442166645,4.8846492052078245
cummulative feedback,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
e,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3
buffer size,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0
human model,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
tau,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001
total_success,0.0,1.0,2.0,3.0,4.0,5.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0
total_success_div_episode,0.0,1.0,1.0,1.0,1.0,1.0,1.0,0.8571428571428571,0.75,0.6666666666666666,0.6,0.5454545454545454,0.5
total_policy_loss_agent,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
total_policy_loss_hm,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
success_this_episode,0.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0
timesteps_this_episode,0.0,130.0,145.0,196.0,164.0,206.0,202.0,67.0,183.0,72.0,83.0,85.0,25.0
