,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,1000.0,1999.0,2458.0,2993.0,3992.0,4991.0,5663.0,6662.0,7387.0,8386.0,9049.0,10048.0,11047.0,12046.0,13045.0,14044.0,15043.0,16042.0,17041.0,18040.0,19039.0
Episode reward,0.0,-65.1956006802506,-52.27679403956299,76.65641922412526,75.49610400766375,-40.909536334182036,-41.7862213216903,71.4362612845872,-37.480388192769496,67.7824269823763,-41.73154601058394,72.95810489710729,-37.57999223408878,-40.55482744312144,-40.83830674483613,-41.6476053567088,-40.25918615835352,-40.819914274786335,-41.78417850276322,-40.710153730214074,-41.77364739758455,-40.52310416665948
Episode feedback,0.8,0.01903807613322838,0.29659318607555796,0.1921397375717473,0.1797752805622186,0.1302605209115626,0.0901803606310818,0.07004470928458315,0.04609218432255292,0.02762430935411007,0.02204408815426444,0.007552870079225272,0.00901803606310818,0.00901803606310818,0.00100200400701202,0.00400801602804808,0.00200400801402404,0.0,0.0,0.0,0.0,0.0
total seconds,0.0,43.805222272872925,103.38069653511047,129.16984939575195,158.90282821655273,211.0780897140503,261.5455939769745,295.26089096069336,343.9401936531067,379.124977350235,426.6310884952545,458.0747401714325,504.7922434806824,551.7571287155151,598.4697065353394,645.2912621498108,692.183748960495,738.8556723594666,785.6811096668243,832.647411108017,878.897754907608,925.5193629264832
total minutes,0.0,0.7300870378812154,1.723011608918508,2.1528308232625326,2.648380470275879,3.5179681619008383,4.359093232949575,4.921014849344889,5.732336560885112,6.318749622503916,7.110518141587575,7.634579002857208,8.413204058011372,9.195952145258586,9.974495108922323,10.754854369163514,11.53639581600825,12.314261205991109,13.09468516111374,13.877456851800282,14.6482959151268,15.425322715441386
cummulative feedback,0.0,19.0,315.0,403.0,499.0,629.0,719.0,766.0,812.0,832.0,854.0,859.0,868.0,877.0,878.0,882.0,884.0,884.0,884.0,884.0,884.0,884.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,998.0,998.0,458.0,534.0,998.0,998.0,671.0,998.0,724.0,998.0,662.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
