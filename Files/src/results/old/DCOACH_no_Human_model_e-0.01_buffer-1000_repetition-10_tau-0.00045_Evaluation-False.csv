,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,1000.0,1948.0,2568.0,3194.0,3510.0,4509.0,5508.0,6507.0,7506.0,8505.0,9504.0,10503.0,11502.0,12501.0,13500.0,14499.0,15498.0,16442.0,17441.0,18440.0,19439.0
Episode reward,0.0,-71.82217672299116,50.4643895287446,71.41802451848253,72.37336831317691,86.39587460936424,-43.96677441751854,-39.480632109059925,-35.80028546128527,-38.87539335980161,-39.54418529513021,-36.923761899856636,-38.11937891043904,-38.34035720708752,-37.85892651431729,-35.8508694533473,-38.83624303583577,-39.29714407001708,64.04475818421508,-39.854774532199166,-37.0889858712906,-38.94796059732921
Episode feedback,0.8,0.01102204407713222,0.2639915519915612,0.19709208368805803,0.17279999972352,0.14603174556815318,0.09619238467315393,0.06212424843474524,0.054108216378649085,0.026052104182312522,0.00901803606310818,0.012024048084144241,0.0050100200350601,0.0060120240420721205,0.00400801602804808,0.00200400801402404,0.0,0.0,0.0,0.00100200400701202,0.00100200400701202,0.0
total seconds,0.0,43.68991231918335,99.3761088848114,134.08830857276917,168.66989135742188,186.119699716568,236.83614945411682,286.1182520389557,334.92306780815125,382.65245246887207,429.7549583911896,477.04747462272644,524.3778824806213,571.5097205638885,618.3259301185608,665.1774485111237,712.3316423892975,759.3254392147064,803.9292163848877,850.4257934093475,896.5558640956879,943.1184935569763
total minutes,0.0,0.7281652053197225,1.6562684814135233,2.234805142879486,2.8111648559570312,3.1019949952761334,3.9472691575686136,4.768637533982595,5.582051130135854,6.377540874481201,7.162582639853159,7.950791243712107,8.739631374677023,9.525162009398143,10.30543216864268,11.086290808518728,11.872194039821625,12.655423986911774,13.398820273081462,14.173763223489125,14.942597734928132,15.718641559282938
cummulative feedback,0.0,11.0,261.0,383.0,491.0,537.0,633.0,695.0,749.0,775.0,784.0,796.0,801.0,807.0,811.0,813.0,813.0,813.0,813.0,814.0,815.0,815.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,998.0,947.0,619.0,625.0,315.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,943.0,998.0,998.0,998.0
e,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
