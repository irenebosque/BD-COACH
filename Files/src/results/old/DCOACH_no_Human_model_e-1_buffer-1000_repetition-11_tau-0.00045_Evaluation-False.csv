,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30
Accumulated time steps,0.0,463.0,732.0,1290.0,1753.0,2114.0,2375.0,2736.0,3160.0,3613.0,4590.0,4860.0,5226.0,6101.0,6713.0,7060.0,8059.0,9058.0,9375.0,9875.0,10507.0,11297.0,12247.0,13040.0,13993.0,14595.0,15483.0,16409.0,17319.0,18318.0,19317.0
Episode reward,0.0,80.79192045162662,86.9703120002567,73.90059735256023,76.59572004079222,82.65656801224347,87.68571151826771,82.9984514275404,83.11949324922092,80.11131448177849,61.80057788031211,85.59300692909528,82.80664772940064,64.62004589852722,77.11381747705087,82.84454750447678,-33.17798194303608,-25.92418956093734,90.08514610646489,78.36554080187443,79.22825666260034,78.33895356518093,68.42025339941135,79.01078435872519,66.02311001985765,84.61510554499537,72.08716772036462,70.20008765993202,69.29434603722211,-30.948532569905908,-27.313896165735
Episode feedback,0.8,0.42950108366702583,0.27238805868511917,0.28545780918230196,0.20562770518262402,0.14444444404320989,0.146153845591716,0.19722222167438272,0.17257683174331717,0.11283185815745164,0.0922131146596177,0.08921933052334821,0.07397260253706137,0.05377574364556551,0.04255319141971654,0.026011560618463696,0.024048096168288482,0.02104208414725242,0.012658227808043583,0.01002004006008008,0.004754358154113537,0.005069708485336237,0.004214963114631229,0.0012626262610320375,0.003151260500891533,0.0016638935080467662,0.0,0.0021621621598246895,0.001100110009790858,0.0,0.0
total seconds,0.0,29.01295280456543,45.58483934402466,78.61823034286499,104.72444462776184,124.4290235042572,138.95514154434204,159.43953704833984,183.05918264389038,207.04936003684998,256.44967222213745,270.78746914863586,289.6351435184479,332.43800830841064,362.5908839702606,380.0395517349243,427.8831899166107,475.43198823928833,491.16363763809204,515.3542723655701,545.5500206947327,583.0545651912689,627.8576483726501,665.6136407852173,710.4969782829285,739.0385086536407,780.5100617408752,823.9093940258026,866.6551470756531,913.3031446933746,959.9979202747345
total minutes,0.0,0.4835492134094238,0.759747322400411,1.31030383904775,1.7454074104626973,2.0738170584042868,2.315919025739034,2.6573256174723308,3.050986377398173,3.450822667280833,4.274161203702291,4.513124485810597,4.827252391974131,5.540633471806844,6.043181399504344,6.333992528915405,7.131386498610179,7.923866470654805,8.186060627301535,8.589237872759501,9.092500344912212,9.717576086521149,10.464294139544169,11.09356067975362,11.841616304715474,12.31730847756068,13.008501029014587,13.731823233763377,14.444252451260885,15.221719078222911,15.999965337912242
cummulative feedback,0.0,198.0,271.0,430.0,525.0,577.0,615.0,686.0,759.0,810.0,900.0,924.0,951.0,998.0,1024.0,1033.0,1057.0,1078.0,1082.0,1087.0,1090.0,1094.0,1098.0,1099.0,1102.0,1103.0,1103.0,1105.0,1106.0,1106.0,1106.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,461.0,268.0,557.0,462.0,360.0,260.0,360.0,423.0,452.0,976.0,269.0,365.0,874.0,611.0,346.0,998.0,998.0,316.0,499.0,631.0,789.0,949.0,792.0,952.0,601.0,887.0,925.0,909.0,998.0,998.0
e,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
