,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,649.0,1229.0,1931.0,2930.0,3424.0,4423.0,5422.0,6421.0,7420.0,8080.0,9079.0,10078.0,11077.0,12076.0,13075.0,14074.0,15032.0,16031.0,17030.0,18029.0,19028.0
Episode reward,0.0,66.34883072951706,73.24078658013033,69.94904872162678,-39.859196369482355,82.04957061500207,-36.7969350092565,-33.00194245101421,-31.046750019649103,-30.87522898081432,77.18707210326536,-32.397937637519284,-31.977226941479408,-30.4367042957466,-31.954406974056237,-32.52088938523436,-33.542565290549405,67.43942144168525,-31.34379920495157,-29.84219229629889,-32.628087239494924,-31.643596419826483
Episode feedback,0.8,0.3786707876682059,0.34542314275401875,0.2881597713435667,0.17835671324813956,0.15415821469744784,0.1252505008765025,0.07314629251187746,0.04609218432255292,0.03106212421737262,0.016691957486051658,0.01803607212621636,0.014028056098168281,0.0050100200350601,0.00801603205609616,0.0030060120210360602,0.0,0.00417972831329182,0.00200400801402404,0.00100200400701202,0.0,0.0
total seconds,0.0,41.19284439086914,78.69164657592773,121.62069749832153,177.0614697933197,204.21080255508423,256.6438105106354,306.59697008132935,355.05560183525085,403.1796360015869,435.37865829467773,482.9084839820862,530.3998816013336,577.4875326156616,624.6182022094727,671.737619638443,718.6325871944427,763.7303564548492,810.7657699584961,857.7043032646179,904.0181663036346,950.5042221546173
total minutes,0.0,0.6865474065144856,1.3115274429321289,2.0270116249720256,2.9510244965553283,3.4035133759180707,4.277396841843923,5.109949501355489,5.917593363920847,6.719660600026448,7.256310971577962,8.04847473303477,8.839998026688894,9.624792210261027,10.410303370157878,11.19562699397405,11.977209786574045,12.728839274247488,13.512762832641602,14.295071721076965,15.06696943839391,15.841737035910288
cummulative feedback,0.0,245.0,445.0,647.0,825.0,901.0,1026.0,1099.0,1145.0,1176.0,1187.0,1205.0,1219.0,1224.0,1232.0,1235.0,1235.0,1239.0,1241.0,1242.0,1242.0,1242.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,647.0,579.0,701.0,998.0,493.0,998.0,998.0,998.0,998.0,659.0,998.0,998.0,998.0,998.0,998.0,998.0,957.0,998.0,998.0,998.0,998.0
e,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
