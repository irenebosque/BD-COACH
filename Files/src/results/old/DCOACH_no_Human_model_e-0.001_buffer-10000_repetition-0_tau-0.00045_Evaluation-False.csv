,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,922.0,1921.0,2920.0,3468.0,4467.0,5466.0,6465.0,7258.0,7848.0,8847.0,9846.0,10845.0,11844.0,12843.0,13842.0,14841.0,15840.0,16839.0,17838.0,18837.0,19836.0
Episode reward,0.0,57.14713289037278,-38.847963092519805,-34.381998094195666,79.16542778515907,-33.63313360159305,-33.24010517498119,-31.328426589159243,74.29865606971731,79.28138197789167,-33.13539755461979,-31.270198929006657,-29.817888097293764,-29.30796489510348,-31.241384909755446,-31.18330551958635,-31.038179715707333,-29.604804171011402,-31.580268868931334,-29.72958591169621,-30.532924106067988,-29.796496776371537
Episode feedback,0.8,0.46521739079867674,0.32865731429994255,0.20240480941642805,0.20109689177130366,0.12124248484845443,0.06613226446279333,0.052104208364625045,0.04545454539715335,0.015280135797487037,0.014028056098168281,0.007014028049084141,0.0100200400701202,0.00200400801402404,0.0030060120210360602,0.00100200400701202,0.0,0.0,0.0,0.0,0.0,0.0
total seconds,0.0,59.83010005950928,121.98389911651611,179.18178153038025,211.17772388458252,262.775372505188,314.4548578262329,364.8340730667114,406.00654196739197,435.76422214508057,486.50783348083496,534.6014006137848,582.1992921829224,629.2243285179138,677.2061898708344,726.0527596473694,776.5567126274109,826.0038509368896,874.1814420223236,920.5803632736206,966.8872458934784,1012.858204126358
total minutes,0.0,0.9971683343251546,2.0330649852752685,2.9863630255063374,3.5196287314097088,4.379589541753133,5.240914297103882,6.08056788444519,6.766775699456533,7.262737035751343,8.108463891347249,8.91002334356308,9.70332153638204,10.48707214196523,11.286769831180573,12.100879327456157,12.942611877123515,13.76673084894816,14.56969070037206,15.343006054560343,16.114787431557975,16.880970068772633
cummulative feedback,0.0,428.0,756.0,958.0,1068.0,1189.0,1255.0,1307.0,1343.0,1352.0,1366.0,1373.0,1383.0,1385.0,1388.0,1389.0,1389.0,1389.0,1389.0,1389.0,1389.0,1389.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,920.0,998.0,998.0,547.0,998.0,998.0,998.0,792.0,589.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
