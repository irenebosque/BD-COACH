,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,1000.0,1802.0,2387.0,2849.0,3848.0,4847.0,5846.0,6509.0,7508.0,8471.0,9470.0,10469.0,11468.0,12467.0,13466.0,14465.0,15464.0,16463.0,17462.0,18461.0,19377.0
Episode reward,0.0,-50.478209106893594,61.60995343502912,74.07102478095018,79.02715160563373,-44.0703983621457,-39.584304452180234,-40.596771605647554,75.00595444045445,-37.7881667063752,62.48897103287501,-39.71701748738377,-38.449035745132605,-37.125236005793894,-37.83220141433481,-36.007804993707744,-36.507718584455,-36.47550964277709,-38.75000171332377,-37.977032361715096,-35.65920945361597,62.80548815032641
Episode feedback,0.8,0.34268537039811087,0.3133583017311382,0.2208904105806671,0.18438177834190503,0.10120240470821402,0.10721442875028614,0.06212424843474524,0.0528700905545769,0.024048096168288482,0.022869022845250497,0.0100200400701202,0.0100200400701202,0.0050100200350601,0.0030060120210360602,0.00200400801402404,0.00200400801402404,0.00100200400701202,0.00100200400701202,0.0,0.0,0.001092896173668966
total seconds,0.0,60.514267444610596,109.3554310798645,142.77689480781555,168.59456253051758,220.14137506484985,271.4533202648163,321.0381107330322,353.9426577091217,401.56136417388916,447.11069107055664,494.1807143688202,541.2620167732239,588.2465054988861,635.2160792350769,682.4462537765503,729.4675807952881,776.404970407486,823.3106944561005,870.1846945285797,917.100115776062,959.9429247379303
total minutes,0.0,1.0085711240768434,1.8225905179977417,2.3796149134635924,2.809909375508626,3.6690229177474976,4.524222004413605,5.350635178883871,5.899044295152028,6.692689402898153,7.451844851175944,8.236345239480336,9.021033612887065,9.804108424981434,10.586934653917949,11.374104229609172,12.157793013254802,12.940082840124767,13.721844907601675,14.503078242142996,15.285001929601034,15.999048745632171
cummulative feedback,0.0,342.0,593.0,722.0,807.0,908.0,1015.0,1077.0,1112.0,1136.0,1158.0,1168.0,1178.0,1183.0,1186.0,1188.0,1190.0,1191.0,1192.0,1192.0,1192.0,1193.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,998.0,801.0,584.0,461.0,998.0,998.0,998.0,662.0,998.0,962.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,915.0
e,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
