,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,1000.0,1333.0,2332.0,3331.0,3566.0,4565.0,5564.0,6563.0,7562.0,8561.0,9560.0,10559.0,11558.0,12557.0,13556.0,14555.0,15554.0,16553.0,17552.0,18551.0,19550.0
Episode reward,0.0,-54.226533456680194,80.81426576998463,-73.16164715742175,-54.92569962791897,85.96087306094002,-66.84968743591189,-63.1157481330518,-67.54428260405085,-65.3846661688744,-69.35952555045401,-70.34032816032965,-80.97428141750017,-67.4163190446576,-69.77204917819999,-69.29910372814484,-71.79424985991535,-67.67300166472764,-70.51699727444057,-68.34364606746549,-71.995065493722,-69.20367190545755
Episode feedback,0.8,0.3226452902578705,0.2710843365328785,0.10621242474327412,0.17835671324813956,0.1324786319124845,0.08116232456797362,0.06112224442773322,0.04408817630852888,0.0300601202103606,0.02304609216127646,0.0050100200350601,0.0050100200350601,0.0050100200350601,0.00801603205609616,0.0,0.00200400801402404,0.0,0.0,0.0,0.0,0.0
total seconds,0.0,79.12088251113892,106.53710341453552,171.33427357673645,242.3158609867096,258.41893887519836,318.1151444911957,375.80120849609375,431.5486464500427,486.32944440841675,543.0110137462616,595.6474621295929,648.1407372951508,700.3809599876404,754.4115478992462,807.4679448604584,859.9967813491821,912.4071354866028,964.2991092205048,1016.1881945133209,1067.7766222953796,1120.769445180893
total minutes,0.0,1.3186813751856485,1.7756183902422586,2.8555712262789408,4.038597683111827,4.306982314586639,5.301919074853261,6.263353474934896,7.192477440834045,8.10549074014028,9.050183562437693,9.92745770215988,10.802345621585847,11.673015999794007,12.57352579832077,13.45779908100764,14.333279689153036,15.20678559144338,16.071651820341746,16.93646990855535,17.796277038256328,18.679490753014882
cummulative feedback,0.0,322.0,412.0,518.0,696.0,727.0,808.0,869.0,913.0,943.0,966.0,971.0,976.0,981.0,989.0,989.0,991.0,991.0,991.0,991.0,991.0,991.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,998.0,332.0,998.0,998.0,234.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
buffer size,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0
human model,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
