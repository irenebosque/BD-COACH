,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29
Accumulated time steps,0.0,379.0,725.0,1189.0,1463.0,2462.0,2704.0,2955.0,3324.0,4213.0,5212.0,6211.0,6615.0,7199.0,7436.0,8316.0,8628.0,9114.0,10113.0,11112.0,11947.0,12946.0,13611.0,14450.0,15449.0,16005.0,17004.0,17942.0,18748.0,19554.0
Episode reward,0.0,82.1798931104787,84.41795516596542,79.23111485480437,87.33896506579593,-62.37290898063386,85.46924319135876,87.4075832152746,84.78638133098187,60.949380353008095,-45.00764274468796,-49.23514034222081,82.25645470390471,77.11511089032368,91.51474513508455,69.90952115962364,88.72422545274304,85.50622120432385,-24.523348207440335,-20.728554200305116,83.4761445678671,-23.109661885348018,85.62527897765578,83.30042830758562,-28.295641474198696,89.97027866410743,-28.653834500883207,75.3536161641907,78.98903226400986,76.80273935385834
Episode feedback,0.8,0.43236074155872484,0.3652173902457467,0.3023758092821257,0.2783882773685411,0.07615230453291352,0.14522821516502815,0.111999999552,0.13586956484818052,0.09459459448806914,0.06312625244175726,0.037074148259444745,0.03722084358009716,0.03945111485514389,0.025423728705831657,0.01706484639696832,0.01607717036631135,0.012371133995111064,0.00801603205609616,0.0050100200350601,0.0023980815318967847,0.0030060120210360602,0.0,0.0035799522630310834,0.00100200400701202,0.0,0.0,0.0,0.0,0.0
total seconds,0.0,25.9345383644104,51.5930757522583,82.56271767616272,100.95345735549927,151.41749119758606,165.2442090511322,179.20916724205017,199.72119736671448,245.91987299919128,297.9728813171387,349.51839447021484,370.91843724250793,402.7376358509064,414.4576907157898,457.8251464366913,473.14099049568176,496.7470808029175,543.5187835693359,589.9042210578918,628.7015657424927,674.9315741062164,706.3189389705658,745.9642357826233,792.7025306224823,819.3162698745728,866.3912215232849,910.4287083148956,948.0756533145905,985.8514504432678
total minutes,0.0,0.43224230607350667,0.8598845958709717,1.376045294602712,1.6825576225916545,2.523624853293101,2.754070150852203,2.9868194540341695,3.3286866227785747,4.0986645499865215,4.966214688618978,5.825306574503581,6.181973954041799,6.71229393084844,6.907628178596497,7.630419107278188,7.88568317492803,8.279118013381957,9.058646392822265,9.83173701763153,10.478359429041545,11.24885956843694,11.771982316176096,12.432737263043721,13.211708843708038,13.655271164576213,14.439853692054749,15.17381180524826,15.801260888576508,16.430857507387795
cummulative feedback,0.0,163.0,289.0,429.0,505.0,581.0,616.0,644.0,694.0,778.0,841.0,878.0,893.0,916.0,922.0,937.0,942.0,948.0,956.0,961.0,963.0,966.0,966.0,969.0,970.0,970.0,970.0,970.0,970.0,970.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,377.0,345.0,463.0,273.0,998.0,241.0,250.0,368.0,888.0,998.0,998.0,403.0,583.0,236.0,879.0,311.0,485.0,998.0,998.0,834.0,998.0,664.0,838.0,998.0,555.0,998.0,937.0,805.0,805.0
e,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
buffer size,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
