,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29
Accumulated time steps,0.0,749.0,1120.0,1703.0,1945.0,2385.0,2750.0,3275.0,3728.0,4275.0,5073.0,6072.0,6790.0,7763.0,8229.0,9228.0,10018.0,10560.0,11455.0,11921.0,12291.0,12590.0,13589.0,14274.0,15154.0,15715.0,16359.0,17358.0,18357.0,19356.0
Episode reward,0.0,64.79731746191518,82.04398630859272,69.94464380296718,90.31219864262142,79.69254096477783,83.73129918772197,78.0551304046215,83.86937499132101,79.1475356199178,65.57377690543431,-38.38927066034214,63.574974152340495,58.90720376468781,81.33406983732198,-38.47189539464492,70.14647818093621,77.63194883317296,70.23206146163777,86.52853280466596,90.33483068464406,92.36555229578875,-27.06999672072277,78.57540448595681,69.36912678388674,81.60856475941588,82.97228024865453,-27.878815992939614,-24.780387640490808,-30.86129588917496
Episode feedback,0.8,0.3547523422292472,0.3270270261431702,0.1683848794357648,0.24896265456861968,0.18678815447200875,0.19505494451907981,0.16030534320552414,0.14601769879199625,0.08791208775107676,0.08782935999017646,0.056112224392673125,0.04463040440079442,0.02983539091580721,0.01720430103827032,0.0100200400701202,0.005069708485336237,0.0018484288320731446,0.010067114082698978,0.00215053762978379,0.005420054185853512,0.003355704686725823,0.00400801602804808,0.002923976603912315,0.0,0.007142857130102041,0.0015552099509250235,0.0,0.00200400801402404,0.0
total seconds,0.0,45.31357979774475,68.5941276550293,100.5178370475769,115.17162823677063,139.68091344833374,160.33271408081055,188.82524728775024,213.44838666915894,241.51516938209534,282.0920145511627,331.3780629634857,366.65831565856934,413.71384167671204,436.3390073776245,483.71799993515015,521.158533334732,546.9224555492401,589.116441488266,611.3599855899811,629.4491765499115,644.0927994251251,690.8098320960999,723.0457065105438,764.2702569961548,791.0846946239471,821.5869591236115,868.3150320053101,914.9383232593536,961.7729442119598
total minutes,0.0,0.7552263299624126,1.1432354609171549,1.6752972841262816,1.9195271372795104,2.3280152241388956,2.6722119013468424,3.1470874547958374,3.5574731111526487,4.025252823034922,4.701533575852712,5.522967716058095,6.110971927642822,6.895230694611867,7.272316789627075,8.061966665585835,8.685975555578867,9.115374259154002,9.818607358137767,10.18933309316635,10.490819609165191,10.734879990418753,11.513497201601664,12.050761775175731,12.73783761660258,13.18474491039912,13.693115985393524,14.471917200088502,15.24897205432256,16.02954907019933
cummulative feedback,0.0,265.0,386.0,484.0,544.0,626.0,697.0,781.0,847.0,895.0,965.0,1021.0,1053.0,1082.0,1090.0,1100.0,1104.0,1105.0,1114.0,1115.0,1117.0,1118.0,1122.0,1124.0,1124.0,1128.0,1129.0,1129.0,1131.0,1131.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,747.0,370.0,582.0,241.0,439.0,364.0,524.0,452.0,546.0,797.0,998.0,717.0,972.0,465.0,998.0,789.0,541.0,894.0,465.0,369.0,298.0,998.0,684.0,879.0,560.0,643.0,998.0,998.0,998.0
e,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
buffer size,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
