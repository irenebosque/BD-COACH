,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22
Accumulated time steps,0.0,930.0,1277.0,2052.0,2402.0,2828.0,3827.0,4826.0,5825.0,6824.0,7823.0,8822.0,9821.0,10820.0,11819.0,12818.0,13817.0,14816.0,15815.0,16814.0,17813.0,18812.0,19811.0
Episode reward,0.0,54.376329126065116,84.64442858137906,67.27071632182654,84.51278636504874,82.77370112118909,-34.42170652143426,-36.236200772240636,-32.67227177419868,-29.752209683645255,-32.34380961593018,-34.53116326447319,-32.322433351292545,-30.897415815448362,-32.58362137491273,-31.823795923601075,-32.52666407083973,-31.176170232735736,-32.25393740685892,-31.41910305467967,-29.996417681768612,-33.27720296191096,-32.486720145964256
Episode feedback,0.8,0.4116379305909074,0.3439306348441311,0.2713178291068245,0.24068767839344504,0.17647058782006922,0.15330661307283908,0.0801603205609616,0.07014028049084141,0.04609218432255292,0.02104208414725242,0.01603206411219232,0.013026052091156261,0.0060120240420721205,0.0060120240420721205,0.0,0.00100200400701202,0.0,0.0,0.0,0.0,0.0,0.0
total seconds,0.0,59.07692527770996,81.27233457565308,126.87632203102112,147.5640742778778,171.56691908836365,225.08583164215088,275.30113649368286,324.9222719669342,373.5526354312897,420.97117257118225,468.6036231517792,515.9794354438782,563.3634991645813,610.6742086410522,657.5270833969116,704.7017843723297,751.6855127811432,798.7035481929779,845.7892816066742,892.9481790065765,939.7026410102844,986.3063113689423
total minutes,0.0,0.984615421295166,1.354538909594218,2.1146053671836853,2.45940123796463,2.8594486514727273,3.7514305273691813,4.5883522748947145,5.415371199448903,6.225877257188161,7.016186209519704,7.810060385862986,8.59965725739797,9.389391652743022,10.17790347735087,10.95878472328186,11.745029739538829,12.52809187968572,13.311725803216298,14.096488026777903,14.88246965010961,15.66171068350474,16.438438522815705
cummulative feedback,0.0,382.0,501.0,711.0,795.0,870.0,1023.0,1103.0,1173.0,1219.0,1240.0,1256.0,1269.0,1275.0,1281.0,1281.0,1282.0,1282.0,1282.0,1282.0,1282.0,1282.0,1282.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,928.0,346.0,774.0,349.0,425.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
