,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,479.0,1478.0,2477.0,3020.0,3717.0,4716.0,5715.0,6714.0,7713.0,8712.0,9711.0,10710.0,11709.0,12708.0,13707.0,14706.0,15705.0,16704.0,17703.0,18702.0,19701.0
Episode reward,0.0,76.05139591635901,-39.20243450657568,-36.43116755530132,78.46377007727514,74.9438241930858,-33.30918693309867,-32.84449569649536,-33.90256181187761,-33.512800658666855,-31.427589824921004,-35.26780848794435,-34.283152732700195,-33.036839025792254,-34.977540638443735,-33.47761166924697,-34.02022538352443,-33.93919060349887,-32.78964124713055,-33.78845546047828,-33.610937096001976,-33.847486176261754
Episode feedback,0.8,0.4570230598385261,0.350701402454207,0.24749498973196896,0.20479704759262538,0.1508620687487614,0.10020040070120201,0.06112224442773322,0.033066132231396664,0.014028056098168281,0.02104208414725242,0.012024048084144241,0.0060120240420721205,0.0050100200350601,0.0,0.0,0.00100200400701202,0.0,0.00100200400701202,0.0,0.0,0.0
total seconds,0.0,31.25246024131775,93.44698739051819,150.68379497528076,181.33122372627258,218.8161425590515,269.6956980228424,318.8711009025574,366.8887405395508,413.9080889225006,461.4607379436493,508.89745235443115,556.0457706451416,603.2043378353119,650.444055557251,697.2552614212036,744.2944688796997,791.3669104576111,838.3572108745575,884.7882583141327,931.2531185150146,977.7138864994049
total minutes,0.0,0.5208743373552959,1.55744978984197,2.511396582921346,3.022187062104543,3.646935709317525,4.494928300380707,5.314518348375956,6.1148123423258465,6.898468148708344,7.691012299060821,8.481624205907186,9.26742951075236,10.053405630588532,10.840734259287517,11.620921023686726,12.404907814661662,13.189448507626851,13.972620181242625,14.74647097190221,15.520885308583578,16.29523144165675
cummulative feedback,0.0,218.0,568.0,815.0,926.0,1031.0,1131.0,1192.0,1225.0,1239.0,1260.0,1272.0,1278.0,1283.0,1283.0,1283.0,1284.0,1284.0,1285.0,1285.0,1285.0,1285.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,477.0,998.0,998.0,542.0,696.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
