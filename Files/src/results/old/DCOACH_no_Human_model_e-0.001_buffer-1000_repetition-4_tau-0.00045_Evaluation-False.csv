,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,1000.0,1632.0,2128.0,2772.0,3771.0,4770.0,5769.0,6768.0,7767.0,8766.0,9765.0,10764.0,11763.0,12762.0,13761.0,14760.0,15759.0,16758.0,17757.0,18756.0,19755.0
Episode reward,0.0,-52.2013570493571,67.76181375060327,75.13668627216428,70.91741921343313,-42.34200884126627,-39.130601716466806,-36.41642269296685,-39.15053514881608,-34.415452273174544,-38.845764943648675,-36.121726326054905,-38.28938753368974,-38.39326817221991,-35.872684627369374,-37.907976736074886,-37.81394215298609,-38.21347868051658,-33.9131319975534,-36.314633143345574,-37.96611284208956,-38.1927031542813
Episode feedback,0.8,0.35170340646121906,0.3122028521201223,0.1979797975798388,0.2068429234730281,0.14729458903076695,0.09318637265211786,0.054108216378649085,0.03406813623840868,0.024048096168288482,0.01803607212621636,0.01703406811920434,0.0100200400701202,0.0030060120210360602,0.0060120240420721205,0.00100200400701202,0.0030060120210360602,0.00100200400701202,0.0,0.0,0.0,0.0
total seconds,0.0,60.06664538383484,98.95578145980835,126.99582290649414,163.36698365211487,216.89561676979065,267.58366227149963,316.4916191101074,364.2494716644287,411.69117045402527,459.2556493282318,506.57931423187256,553.541323184967,600.2928304672241,647.5530760288239,694.4909105300903,741.6396644115448,788.7006018161774,835.6187331676483,882.409184217453,929.0132412910461,975.5468134880066
total minutes,0.0,1.0011107563972472,1.6492630243301392,2.116597048441569,2.722783060868581,3.6149269461631777,4.459727704524994,5.274860318501791,6.070824527740479,6.861519507567087,7.654260822137197,8.44298857053121,9.225688719749451,10.00488050778707,10.792551267147065,11.574848508834839,12.360661073525746,13.145010030269622,13.926978886127472,14.70681973695755,15.483554021517437,16.259113558133443
cummulative feedback,0.0,351.0,548.0,646.0,779.0,926.0,1019.0,1073.0,1107.0,1131.0,1149.0,1166.0,1176.0,1179.0,1185.0,1186.0,1189.0,1190.0,1190.0,1190.0,1190.0,1190.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,998.0,631.0,495.0,643.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0,998.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0,1000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
