,0,1,2,3,4,5
Accumulated time steps,0.0,668.0,1335.0,2002.0,2669.0,3336.0
Episode reward,0.0,122.97107032490045,122.94869662095755,124.61345301196714,119.78735478735956,168.17609269851948
Episode feedback,0.8,0.0,0.0,0.05255255247364481,0.0,0.0
total seconds,0.0,74.39723896980286,149.73255038261414,225.94167375564575,302.145610332489,378.1603274345398
total minutes,0.0,1.2399539828300477,2.495542506376902,3.765694562594096,5.035760172208151,6.302672123908996
cummulative feedback,0.0,0.0,0.0,35.0,35.0,35.0
e,0.5,0.5,0.5,0.5,0.5,0.5
buffer size,1500.0,1500.0,1500.0,1500.0,1500.0,1500.0
human model,0.0,0.0,0.0,0.0,0.0,0.0
tau,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001
total_success,0.0,0.0,0.0,0.0,0.0,0.0
total_success_div_episode,0.0,0.0,0.0,0.0,0.0,0.0
total_policy_loss_agent,0.0,0.0,0.0,0.0,0.0,0.0
total_policy_loss_hm,0.0,0.0,0.0,0.0,0.0,0.0
