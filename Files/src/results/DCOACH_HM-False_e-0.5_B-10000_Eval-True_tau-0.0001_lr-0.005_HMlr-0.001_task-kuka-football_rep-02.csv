,0,1,2,3,4
Accumulated time steps,0.0,168.0,459.0,494.0,611.0
Episode reward,0.0,56.38619004189968,90.32884775102139,30.20537096261978,16.43711192093906
Episode feedback,0.8,0.0,0.0,0.0,0.0
total seconds,0.0,27.15182590484619,67.96040153503418,82.55699181556702,105.54956269264221
total minutes,0.0,0.4525304317474365,1.1326733589172364,1.3759498635927836,1.7591593782107036
cummulative feedback,0.0,0.0,0.0,0.0,0.0
e,0.5,0.5,0.5,0.5,0.5
buffer size,10000.0,10000.0,10000.0,10000.0,10000.0
human model,0.0,0.0,0.0,0.0,0.0
tau,0.0001,0.0001,0.0001,0.0001,0.0001
total_success,0.0,0.0,0.0,0.0,1.0
total_success_div_episode,0.0,0.0,0.0,0.0,0.25
total_policy_loss_agent,0.0,0.0,0.0,0.0,0.0
total_policy_loss_hm,0.0,0.0,0.0,0.0,0.0
success_this_episode,0.0,0.0,0.0,0.0,1.0
timesteps_this_episode,0.0,166.0,290.0,34.0,116.0
