,0,1,2,3,4
Accumulated time steps,0.0,142.0,262.0,393.0,894.0
Episode reward,0.0,65.30424238422651,63.1392787529713,66.88217745274076,108.4148869372498
Episode feedback,0.8,0.3214285691326531,0.41176470242214536,0.046153845798816574,0.091999999816
total seconds,0.0,25.64245295524597,50.510674238204956,75.30562710762024,139.71855664253235
total minutes,0.0,0.4273742159207662,0.8418445706367492,1.255093785127004,2.3286426107088727
cummulative feedback,0.0,45.0,94.0,100.0,146.0
e,0.5,0.5,0.5,0.5,0.5
buffer size,10000.0,10000.0,10000.0,10000.0,10000.0
human model,1.0,1.0,1.0,1.0,1.0
tau,0.0001,0.0001,0.0001,0.0001,0.0001
total_success,0.0,1.0,1.0,2.0,2.0
total_success_div_episode,0.0,1.0,0.5,0.6666666666666666,0.5
total_policy_loss_agent,0.0,0.0,0.0,0.0,0.0
total_policy_loss_hm,0.0,0.04686243087053299,0.09730616211891174,0.11003477871417999,0.047682225704193115
success_this_episode,0.0,1.0,0.0,1.0,0.0
timesteps_this_episode,0.0,140.0,119.0,130.0,500.0
