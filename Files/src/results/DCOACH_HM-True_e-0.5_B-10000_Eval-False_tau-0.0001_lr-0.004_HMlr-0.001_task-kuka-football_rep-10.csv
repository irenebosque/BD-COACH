,0,1,2,3,4
Accumulated time steps,0.0,133.0,197.0,350.0,410.0
Episode reward,0.0,109.28043005700007,37.575216353386864,108.93789912469006,49.72469766042155
Episode feedback,0.8,0.7328244218868365,0.6666666560846563,0.0,0.0
total seconds,0.0,26.140706539154053,44.970404386520386,72.10044622421265,89.443354845047
total minutes,0.0,0.4356784423192342,0.7495067397753398,1.2016741037368774,1.4907225807507833
cummulative feedback,0.0,96.0,138.0,138.0,138.0
e,0.5,0.5,0.5,0.5,0.5
buffer size,10000.0,10000.0,10000.0,10000.0,10000.0
human model,1.0,1.0,1.0,1.0,1.0
tau,0.0001,0.0001,0.0001,0.0001,0.0001
total_success,0.0,0.0,0.0,0.0,0.0
total_success_div_episode,0.0,0.0,0.0,0.0,0.0
total_policy_loss_agent,0.0,0.0,0.0,0.0,0.0
total_policy_loss_hm,0.0,0.006389054469764233,0.08446303009986877,0.184778094291687,0.0505741685628891
success_this_episode,0.0,0.0,0.0,0.0,0.0
timesteps_this_episode,0.0,131.0,63.0,152.0,59.0
