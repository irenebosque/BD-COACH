,0,1,2,3,4,5
Accumulated time steps,0.0,502.0,1003.0,1504.0,1597.0,1798.0
Episode reward,0.0,153.51552285607866,362.8103264249491,196.72541290576095,183.98346874250265,196.0845683565922
Episode feedback,0.8,0.0,0.0,0.0,0.0,0.0
total seconds,0.0,3.522902011871338,7.8586320877075195,12.277412176132202,13.916529893875122,16.27849555015564
total minutes,0.0,0.05871503353118897,0.13097720146179198,0.20462353626887003,0.2319421648979187,0.27130825916926066
cummulative feedback,0.0,0.0,0.0,0.0,0.0,0.0
e,0.1,0.1,0.1,0.1,0.1,0.1
buffer size,6000.0,6000.0,6000.0,6000.0,6000.0,6000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0
tau,0.00015,0.00015,0.00015,0.00015,0.00015,0.00015
total_success,0.0,0.0,0.0,0.0,1.0,2.0
total_success_div_episode,0.0,0.0,0.0,0.0,0.25,0.4
total_policy_loss_agent,0.0,0.0,0.0,0.0,0.0,0.0
total_policy_loss_hm,0.0,0.0,0.0,0.0,0.0,0.0
success_this_episode,0.0,0.0,0.0,0.0,1.0,1.0
