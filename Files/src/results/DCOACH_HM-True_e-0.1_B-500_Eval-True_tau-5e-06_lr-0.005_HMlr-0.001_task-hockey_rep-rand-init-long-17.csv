,0
Episode,"[0, 1, 5, 5, 10, 9, 15, 13, 20, 17]"
Accumulated time steps,"[0, 2, 2002, 4002, 6002, 8002]"
Episode reward,"[0, 61.34622352137247, 147.11353937422936, 215.7908710124858, 179.91557540744796, 155.64784689435757]"
Episode feedback,"[0.9, 0.001999999996, 0.001999999996, 0.011627906841535968, 0.014492753413148502, 0.001999999996]"
total seconds,"[0, 1.1734881401062012, 12.2639741897583, 21.96446990966797, 31.691970825195312, 41.647860527038574]"
total minutes,"[0, 0.019558135668436685, 0.20439956982930502, 0.36607449849446616, 0.5281995137532552, 0.6941310087839763]"
cummulative feedback,"[0, 1, 2, 3, 4, 5]"
e,"[0.1, 0.1, 0.1, 0.1, 0.1, 0.1]"
buffer size,"[500, 500, 500, 500, 500, 500]"
human model,"[True, True, True, True, True, True]"
tau,"[5e-06, 5e-06, 5e-06, 5e-06, 5e-06, 5e-06]"
total_success,"[0, 0, 1754, 3505, 5262, 7014]"
total_success_div_episode,"[0, 0.0, 350.8, 389.44444444444446, 404.7692307692308, 412.5882352941176]"
success_this_episode,"[0, 0, 0, 1, 1, 0]"
timesteps_this_episode,"[0, 500, 500, 86, 69, 500]"
