,0,1,2,3,4,5,6,7,8,9,10,11
Accumulated time steps,0.0,501.0,1001.0,1501.0,1581.0,2081.0,2581.0,3081.0,3581.0,4081.0,4150.0,4650.0
Episode reward,0.0,136.30155686312958,129.93220398589494,222.50259138414444,206.84901289564246,96.26525602114627,134.3387099660501,205.57525148511667,169.8985647960417,120.04055872344598,198.24148841084897,808.1153446623747
Episode feedback,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
total seconds,0.0,1.07875657081604,2.232456684112549,3.2476978302001953,3.548560380935669,4.5024683475494385,5.449499130249023,6.389537572860718,7.332599401473999,8.280447721481323,8.573360919952393,9.661157369613647
total minutes,0.0,0.017979276180267335,0.03720761140187581,0.05412829717000325,0.059142673015594484,0.07504113912582397,0.09082498550415039,0.10649229288101196,0.12220999002456664,0.13800746202468872,0.14288934866587322,0.16101928949356079
cummulative feedback,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
e,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1
buffer size,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0
human model,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
tau,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06,5e-06
total_success,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,2.0
total_success_div_episode,0.0,0.0,0.0,0.0,0.25,0.2,0.16666666666666666,0.14285714285714285,0.125,0.1111111111111111,0.2,0.18181818181818182
total_policy_loss_agent,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
total_policy_loss_hm,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
success_this_episode,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0
timesteps_this_episode,0.0,500.0,500.0,500.0,80.0,500.0,500.0,500.0,500.0,500.0,69.0,500.0
