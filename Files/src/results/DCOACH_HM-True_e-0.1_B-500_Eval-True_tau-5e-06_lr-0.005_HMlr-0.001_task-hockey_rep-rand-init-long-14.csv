,0
Episode,"[0, 0, 1, 0, 1, 5, 4, 5, 4]"
Accumulated time steps,"[0, 2, 2, 1502, 1502]"
Episode reward,"[0, 168.58842228700973, 202.88333839543728, 152.71563437354246, 178.20466830326444]"
Episode feedback,"[0.9, 0.001999999996, 0.0, 0.0, 0.0]"
total seconds,"[0, 1.1505229473114014, 2.2687292098999023, 10.863484144210815, 12.136654138565063]"
total minutes,"[0, 0.019175382455190022, 0.0378121534983317, 0.18105806907018027, 0.2022775689760844]"
cummulative feedback,"[0, 1, 1, 1, 1]"
e,"[0.1, 0.1, 0.1, 0.1, 0.1]"
buffer size,"[500, 500, 500, 500, 500]"
human model,"[True, True, True, True, True]"
tau,"[5e-06, 5e-06, 5e-06, 5e-06, 5e-06]"
total_success,"[0, 0, 0, 1315, 1315]"
total_success_div_episode,"[0, 0.0, 0.0, 328.75, 328.75]"
success_this_episode,"[0, 0, 0, 0, 0]"
timesteps_this_episode,"[0, 500, 500, 500, 500]"
