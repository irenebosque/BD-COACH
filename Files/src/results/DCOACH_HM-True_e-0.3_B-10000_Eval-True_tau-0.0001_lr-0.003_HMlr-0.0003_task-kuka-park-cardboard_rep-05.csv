,0,1,2,3,4,5,6,7,8,9,10,11,12
Accumulated time steps,0.0,154.0,384.0,558.0,642.0,896.0,960.0,1024.0,1254.0,1320.0,1491.0,1565.0,1646.0
Episode reward,0.0,73.74547338139877,65.30688725418388,62.26464227372429,41.47893673586687,73.84722387522605,34.895571254925684,38.1578034178402,62.919216247212375,34.551698147587615,63.943610815199584,35.127998390609044,39.804154371450984
Episode feedback,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
total seconds,0.0,25.864257335662842,60.57065010070801,89.51789593696594,109.18653345108032,146.37289547920227,163.97987914085388,181.58859276771545,216.30057954788208,234.1276650428772,262.7665731906891,281.40934562683105,300.7662675380707
total minutes,0.0,0.4310709555943807,1.0095108350118,1.4919649322827657,1.8197755575180055,2.4395482579867047,2.732997985680898,3.026476546128591,3.605009659131368,3.90212775071462,4.379442886511485,4.690155760447184,5.0127711256345115
cummulative feedback,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
e,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3
buffer size,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0
human model,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
tau,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001
total_success,0.0,1.0,2.0,3.0,3.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0
total_success_div_episode,0.0,1.0,1.0,1.0,0.75,0.8,0.6666666666666666,0.5714285714285714,0.5,0.4444444444444444,0.4,0.36363636363636365,0.3333333333333333
total_policy_loss_agent,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
total_policy_loss_hm,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
success_this_episode,0.0,1.0,1.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
timesteps_this_episode,0.0,152.0,229.0,173.0,83.0,253.0,63.0,63.0,229.0,65.0,170.0,73.0,80.0
