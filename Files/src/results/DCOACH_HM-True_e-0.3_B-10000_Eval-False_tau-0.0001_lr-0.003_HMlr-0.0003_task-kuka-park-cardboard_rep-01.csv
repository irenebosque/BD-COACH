,0,1,2,3
Accumulated time steps,0.0,215.0,442.0,622.0
Episode reward,0.0,88.25071009442948,147.38993998201474,148.5303625692897
Episode feedback,0.8,0.4553990588948401,0.7477876073106743,0.8826815593146282
total seconds,0.0,35.99513506889343,78.33800888061523,121.17371654510498
total minutes,0.0,0.5999189178148906,1.3056334813435873,2.019561942418416
cummulative feedback,0.0,97.0,266.0,424.0
e,0.3,0.3,0.3,0.3
buffer size,10000.0,10000.0,10000.0,10000.0
human model,1.0,1.0,1.0,1.0
tau,0.0001,0.0001,0.0001,0.0001
total_success,0.0,1.0,1.0,1.0
total_success_div_episode,0.0,1.0,0.5,0.3333333333333333
total_policy_loss_agent,0.0,0.0,0.0,0.00044616215745918453
total_policy_loss_hm,0.0,0.07105441391468048,0.14855381846427917,0.189482182264328
success_this_episode,0.0,1.0,0.0,0.0
timesteps_this_episode,0.0,213.0,226.0,179.0
