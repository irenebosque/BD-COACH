,0,1,2,3,4,5,6,7,8,9,10,11,12
Accumulated time steps,0.0,101.0,201.0,301.0,401.0,501.0,601.0,701.0,801.0,901.0,1001.0,1101.0,1201.0
Episode reward,0.0,43.89587009319156,28.61964379976456,97.40528966340555,77.36905316938797,97.74501915333802,50.57732607032882,146.36841720633691,60.952788172110196,451.7609527787161,62.704959849584164,67.80874944382343,72.25804993838422
Episode feedback,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
total seconds,0.0,1.5409975051879883,2.4322779178619385,3.285698652267456,4.160818099975586,5.039891481399536,5.929174423217773,6.811192512512207,7.694909572601318,8.579070568084717,9.45692253112793,10.324023962020874,11.254406929016113
total minutes,0.0,0.02568329175313314,0.04053796529769897,0.0547616442044576,0.06934696833292643,0.08399819135665894,0.09881957372029622,0.11351987520853678,0.12824849287668863,0.1429845094680786,0.15761537551879884,0.17206706603368124,0.18757344881693522
cummulative feedback,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
e,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01
buffer size,15000.0,15000.0,15000.0,15000.0,15000.0,15000.0,15000.0,15000.0,15000.0,15000.0,15000.0,15000.0,15000.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
tau,1e-05,1e-05,1e-05,1e-05,1e-05,1e-05,1e-05,1e-05,1e-05,1e-05,1e-05,1e-05,1e-05
total_success,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,27.0,27.0,27.0,27.0
total_success_div_episode,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3.0,2.7,2.4545454545454546,2.25
total_policy_loss_agent,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
total_policy_loss_hm,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
success_this_episode,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0
timesteps_this_episode,0.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0,100.0
