,0,1,2,3,4
Accumulated time steps,0.0,63.0,132.0,195.0,358.0
Episode reward,0.0,168.08823968142786,151.0316141528053,148.62354557678387,230.66055741658832
Episode feedback,0.9,0.7419354719042666,0.7681159308968706,0.8253968122952887,0.8773006081147202
total seconds,0.0,1.183603048324585,2.7019288539886475,4.128414154052734,9.989054679870605
total minutes,0.0,0.019726717472076417,0.04503214756647746,0.06880690256754557,0.1664842446645101
cummulative feedback,0.0,46.0,99.0,151.0,294.0
e,0.1,0.1,0.1,0.1,0.1
buffer size,500.0,500.0,500.0,500.0,500.0
human model,1.0,1.0,1.0,1.0,1.0
tau,5e-06,5e-06,5e-06,5e-06,5e-06
total_success,0.0,1.0,2.0,3.0,4.0
total_success_div_episode,0.0,1.0,1.0,1.0,1.0
total_policy_loss_agent,0.0,0.0,0.0,0.0,0.000629941001534462
total_policy_loss_hm,0.0,0.2664584219455719,0.16777272522449493,0.14232264459133148,0.18475991487503052
success_this_episode,0.0,1.0,1.0,1.0,1.0
timesteps_this_episode,0.0,62.0,69.0,63.0,163.0
