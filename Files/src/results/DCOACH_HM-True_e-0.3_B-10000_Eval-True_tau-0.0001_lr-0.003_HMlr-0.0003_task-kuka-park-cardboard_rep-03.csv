,0,1,2,3,4,5,6,7,8,9,10,11,12,13
Accumulated time steps,0.0,164.0,355.0,356.0,515.0,778.0,936.0,1030.0,1202.0,1325.0,1826.0,2120.0,2156.0,2222.0
Episode reward,0.0,77.77676323386589,87.5621974422588,0.0,65.80777393674006,121.22685169479122,79.0790268493707,39.393693414821485,75.20082964834137,62.27972865874403,175.19478396742338,83.47548708684099,15.12774220981066,35.04814425654649
Episode feedback,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
total seconds,0.0,26.88530135154724,57.5731143951416,68.68843960762024,96.09686136245728,134.22190976142883,161.5208261013031,182.2352113723755,210.97384524345398,234.66289925575256,297.303866147995,338.60642099380493,353.3385624885559,371.1569182872772
total minutes,0.0,0.4480883558591207,0.9595519065856933,1.1448073267936707,1.6016143560409546,2.2370318293571474,2.692013768355052,3.0372535228729247,3.5162307540575664,3.9110483209292095,4.955064435799916,5.643440349896749,5.888976041475932,6.185948638121287
cummulative feedback,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
e,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3
buffer size,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0
human model,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
tau,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001
total_success,0.0,1.0,2.0,3.0,4.0,5.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0
total_success_div_episode,0.0,1.0,1.0,1.0,1.0,1.0,1.0,0.8571428571428571,0.75,0.6666666666666666,0.6,0.5454545454545454,0.5,0.46153846153846156
total_policy_loss_agent,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
total_policy_loss_hm,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
success_this_episode,0.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
timesteps_this_episode,0.0,162.0,190.0,0.0,158.0,262.0,157.0,93.0,171.0,122.0,500.0,293.0,35.0,65.0
