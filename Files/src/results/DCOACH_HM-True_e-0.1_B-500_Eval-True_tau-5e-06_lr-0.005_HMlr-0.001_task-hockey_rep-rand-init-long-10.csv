,0
Episode,"[0, 0, 1, 0, 1, 5, 4, 5, 4, 10, 7, 10, 7]"
Accumulated time steps,"[0, 2, 2, 1502, 1502, 3002, 3002]"
Episode reward,"[0, 141.8903562000044, 128.90692634506314, 616.5719890840991, 199.26304442916737, 118.26594277279654, 143.02789142836554]"
Episode feedback,"[0.9, 0.001999999996, 0.0, 0.001999999996, 0.0, 0.001999999996, 0.0]"
total seconds,"[0, 1.357083797454834, 2.39345383644104, 10.364291429519653, 10.653717041015625, 18.228520393371582, 19.338955402374268]"
total minutes,"[0, 0.0226180632909139, 0.03989089727401733, 0.1727381904919942, 0.17756195068359376, 0.3038086732228597, 0.32231592337290443]"
cummulative feedback,"[0, 1, 1, 2, 2, 3, 3]"
e,"[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]"
buffer size,"[500, 500, 500, 500, 500, 500, 500]"
human model,"[True, True, True, True, True, True, True]"
tau,"[5e-06, 5e-06, 5e-06, 5e-06, 5e-06, 5e-06, 5e-06]"
total_success,"[0, 0, 0, 1320, 1321, 2626, 2626]"
total_success_div_episode,"[0, 0.0, 0.0, 330.0, 330.25, 375.14285714285717, 375.14285714285717]"
success_this_episode,"[0, 0, 0, 0, 1, 0, 0]"
timesteps_this_episode,"[0, 500, 500, 500, 70, 500, 500]"
