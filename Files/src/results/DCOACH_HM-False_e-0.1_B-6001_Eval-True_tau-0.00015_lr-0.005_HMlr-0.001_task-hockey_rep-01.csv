,0,1,2,3,4,5,6,7,8,9,10
Accumulated time steps,0.0,502.0,1003.0,1504.0,1597.0,1798.0,2299.0,2404.0,2905.0,2996.0,3078.0
Episode reward,0.0,153.51552285607866,362.8103264249491,196.72541290576095,183.98346874250265,196.0845683565922,207.8733041713192,126.48119403490277,204.69203369745074,126.43860045115979,185.55894407829499
Episode feedback,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
total seconds,0.0,3.574070692062378,7.957441568374634,12.4030601978302,14.061231136322021,16.46184229850769,20.93748378753662,22.631633758544922,27.041844367980957,28.663439750671387,30.241448640823364
total minutes,0.0,0.0595678448677063,0.13262402613957722,0.20671766996383667,0.2343538522720337,0.2743640383084615,0.34895806312561034,0.3771938959757487,0.45069740613301595,0.47772399584452313,0.5040241440137228
cummulative feedback,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
e,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1
buffer size,6001.0,6001.0,6001.0,6001.0,6001.0,6001.0,6001.0,6001.0,6001.0,6001.0,6001.0
human model,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
tau,0.00015,0.00015,0.00015,0.00015,0.00015,0.00015,0.00015,0.00015,0.00015,0.00015,0.00015
total_success,0.0,0.0,0.0,0.0,1.0,2.0,2.0,3.0,3.0,4.0,5.0
total_success_div_episode,0.0,0.0,0.0,0.0,0.25,0.4,0.3333333333333333,0.42857142857142855,0.375,0.4444444444444444,0.5
total_policy_loss_agent,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
total_policy_loss_hm,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
success_this_episode,0.0,0.0,0.0,0.0,1.0,1.0,0.0,1.0,0.0,1.0,1.0
