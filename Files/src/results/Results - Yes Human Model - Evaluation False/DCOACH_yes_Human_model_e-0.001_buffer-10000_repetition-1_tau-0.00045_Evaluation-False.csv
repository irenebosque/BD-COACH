,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21
Accumulated time steps,0.0,1000.0,1999.0,2998.0,3997.0,4996.0,5995.0,6905.0,7250.0,8055.0,8520.0,9005.0,9386.0,9675.0,9874.0,10228.0,10525.0,10823.0,11117.0,11398.0,11665.0,11918.0
Episode reward,0.0,-68.54436756289526,-66.03000568494224,-70.7648397424777,-61.227202096427035,-60.89661914325662,-65.11036999296326,47.75221537878131,79.18383370135683,54.06852295756373,75.49179134125013,72.71195131641454,80.55438465063148,83.94971277444978,87.11291642659089,78.25292325417496,82.00384041187343,82.01411625848417,81.04919077565694,82.08535788009033,83.62567075868677,87.30654380250328
Episode feedback,0.8,0.00801603205609616,0.0901803606310818,0.07414829651888949,0.10621242474327412,0.056112224392673125,0.027054108189324542,0.024202420215398878,0.011627906942942131,0.016169154208744832,0.008620689636593341,0.0,0.010526315761772853,0.0,0.00505050502499745,0.014164305908882987,0.003378378366964938,0.0033670033556666553,0.0,0.0035714285586734697,0.0,0.0
total seconds,0.0,45.43777275085449,101.88221836090088,158.09328413009644,216.61631202697754,271.66596126556396,324.701562166214,373.261118888855,391.79390382766724,434.3670611381531,458.85081577301025,484.29141211509705,504.5746819972992,520.0020747184753,531.1013095378876,550.3323709964752,566.3334581851959,582.1863486766815,598.0009281635284,613.2135963439941,627.6580362319946,641.1723427772522
total minutes,0.0,0.7572962125142415,1.6980369726816813,2.6348880688349405,3.610271867116292,4.527766021092733,5.4116927027702335,6.221018648147583,6.529898397127787,7.239451018969218,7.647513596216838,8.071523535251618,8.40957803328832,8.666701245307923,8.851688492298127,9.172206183274588,9.438890969753265,9.703105811278025,9.966682136058807,10.220226605733236,10.460967270533244,10.686205712954203
cummulative feedback,0.0,8.0,98.0,172.0,278.0,334.0,361.0,383.0,387.0,400.0,404.0,404.0,408.0,408.0,409.0,414.0,415.0,416.0,416.0,417.0,417.0,417.0
Ph,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9
steps_that_episode,0.0,998.0,998.0,998.0,998.0,998.0,998.0,909.0,344.0,804.0,464.0,484.0,380.0,288.0,198.0,353.0,296.0,297.0,293.0,280.0,266.0,252.0
e,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001
buffer size,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0
human model,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
