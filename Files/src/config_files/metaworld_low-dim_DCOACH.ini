[GENERAL]
render_delay = 0.001
environment = meta-world
count_down = False
render = True
graph_folder_path = graphs/
eval_save_path = results/
metaworld_env = True
mountaincar_env = False
kuka_env = False
pendulum_env = False
act_func_agent = "tanh"

; CHECK THE FOLLOWING PARAMETERS BEFORE STARTING A TRAIN/EVALUATION
save_results = True
evaluate = False
number_of_repetitions = 10
evaluations_per_training = 5
max_num_of_episodes = 20000
; Before max_time_steps_episode = 500
max_time_steps_episode = 500
max_time_steps_per_repetition = 75000
cut_feedback = 75000
absolute_positions = False
tau = 0.000015
alpha = 0.9
theta = 0.1
task = "plate-slide-v2-goal-observable"
oracle_teacher = True
human_teacher = False
action_factor = 1.


[AGENT]
; CHECK THE FOLLOWING PARAMETERS BEFORE STARTING A TRAIN/EVALUATION
h_threshold = 0.1
buffer_max_size = 15000
human_model_included = True
dim_a = 3
dim_o = 6
e = 0.1
policy_model_learning_rate = 0.001
human_model_learning_rate = 0.001
agent_with_hm_learning_rate = 0.001


n_neurons_agent = 256
action_limit = 1


; YOU DONT NEED TO MODIFY THESE ONES:

agent = DCOACH
buffer_min_size = 20
buffer_sampling_rate = 10
train_end_episode = False
buffer_sampling_size = 20
action_upper_limits = 1
action_lower_limits = -1
save_policy = False
load_policy = False

[TRANSITION_MODEL]
transition_model = full
image_side_length= 64
buffer_max_size = 100006
buffer_min_size = 100
buffer_sampling_rate = 1000000000
train_end_episode = True
buffer_sampling_size = 20
lstm_hidden_state_size = 150
training_sequence_length = 10
number_training_iterations = 20
learning_rate = 0.0005
show_observation = True
show_transition_model_output = True
resize_observation = True
crop_observation = True
occlude_observation = False
save_transitions = True
save_transition_model = False
load_transition_model = False



[FEEDBACK]
key_type = 1
h_up = 0
h_down = 0
h_right = 1
h_left = -1
h_null = 0
